{"0": {
    "doc": "Git 使用指南",
    "title": "Git 使用指南",
    "content": ". | 管理远程仓库 . | git remote add [remote name] [git url] 添加远端地址 | git fetch [origin name] 拉取远端更新到本地但不会合并 | git remote -v 查看远端仓库信息 | git remote show [remote name] 显示远端仓库信息 | git push [remote name] [branch name] 推送本地内容到远端仓库 | git remote rename [remote name1] [remote name2] 重命名远端地址 | git remote rm [remote name]删除远端地址 | . | 分支管理 . | git branch 列出所有本地分支 | git branch -a 查看远端分支 | git branch -d [name] 删除某个分支 | git push origin :[branch_name] 删除远端分支 | git branch -v 查看各个分支最后一个提交对象的信息 | git branch –merged 查看哪些分支已被并入当前分支 | git branch –no-merged 查看尚未合并到当前分支的分支 | git push origin [本地分支]:[远端分支] 推送本地分支到远端分支 | git checkout -b dev2 remotes/origin/dev2 切换本地分支对应的远端分支 | . | 拉取 . | git fetch origin 获取所有的远端代码到本地 | git fetch –all 获取所有远端分支 | git merge origin/[远端分支] 合并远端分支到本地分支 | git checkout -b [本地分支] origin/[远端分支] 在远端分支的基础上分化出一个本地分支 | git checkout –track origin/[远端分支] 设置本地分支跟踪到远端分支 | git branch –set-upstream-to=origin/&lt;branch&gt; &lt;branch&gt; | git pull | . | 分支变基 . | git checkout experiment | git rebase master 切换到experiment分支在主分支上将experiment的提交历史重演 | git rebase [主分支] [特性分支] 取出特性分支然后在主分支上重演 | git checkout master 切换到master分支 | git merge server 合并server分支到当前分支 | git rebase –onto master server client “取出 client 分支，找出 client 分支和 server 分支的共同祖先之后的变化，然后把它们在 master 上重演一遍” | . | 查看每次更新 . | git status | git diff 查看尚未暂存的文件更新了哪些部分 | git diff –staged 查看已暂存文件更新了那些部分 | git commit -am xxxx 本条命令将git add和git commit合并为一条 | . | 取消提交 . | 未push到远程仓库 git reset –soft | –mixed | –hard &lt;commit_id&gt;–mixed 会保留源码,只是将git commit和index 信息回退到了某个版本.–soft 保留源码,只回退到commit信息到某个版本.不涉及index的回退,如果还需要提交,直接commit即可.–hard 源码也会回退到某个版本,commit和index 都会回退到某个版本.(注意,这种方式是改变本地代码仓库源码) | . | 已push到远程仓库git revert &lt;commit_id&gt; | git cherry-pick可以选择某一个分支中的一个或几个commit(s)来进行操作（操作的对象是commit | . | .gitignore 不生效： git rm -r –cached . git add . git commit -m “update .gitignore” . | 撤销工作区readme文件的更改 git checkout – readme.txt、 git reset HEAD xxx 将暂存区的文件撤回到工作区 . | tag . | git tag -a [标签] -m “” 打标签 | git tag -d [标签] 删除标签 | git push origin [标签] 推送标签到远程库 | git push origin –tags 一次性推送本地所有标签到远程库 | . | push 大文件 . | git lfs track xxx 用lfs 追踪xxx指定的大文件 | git lfs track 查看追踪的文件 | cat .gitaddributes 查看追踪文件 | git lfs ls-files 查看已经push的大文件 | git lfs clone &lt;URL&gt; 克隆包含”Git LFS”的文件的远程仓库到本地 | . | git 瘦身 . | git gc –prune=now 触发git gc | | git verify-pack -v .git/objects/pack/*.idx | sort -k 3 -n | tail -3 找出3个最大的文件 | . | | git rev-list –objects –all | grep c43a8da 查看大文件都是谁 | . | git filter-branch –force –index-filter “git rm –cached –ignore-unmatch ‘data/bigfile’” –prune-empty –tag-name-filter cat – –all 移除对某个大文件的引用进行repack | | git for-each-ref –format=’delete %(refname)’ refs/original | git update-ref –stdin | . | git reflog expire –expire=now –all | git gc –prune=now | git count-objects -v 查看pack使用情况 | . | 远程库回退版本 （更改历史） . | git reset –hard 0bfafd | git push -f | . | 远程库回退版本（不改变历史） . | git revert commit-hash 为每个提交创建一个反向的提交 | git push | . | 添加公钥 ssh-keygen -t rsa -C “您的邮箱地址” . | git commit 提交规范 &lt;type&gt;(&lt;scope&gt;): &lt;description&gt; type: . | feat: 新功能（feature） | fix: 修复 bug | chore: 无关生产代码的工作（构建、配置、辅助工具等） | docs: 文档更新 | style: 代码样式调整，不影响代码逻辑 | refactor: 代码重构，既不修复错误也不添加新功能 | test: 添加或修改测试 | . | . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/git.html",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/git.html"
  },"1": {
    "doc": "Go 性能优化工具指南",
    "title": "net/pprof",
    "content": "go tool pprof http://localhost:6060/debug/pprof/heap go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30 go tool pprof http://localhost:6060/debug/pprof/block go tool pprof http://localhost:6060/debug/pprof/mutex curl -o trace.out http://localhost:6060/debug/pprof/trace? seconds=5 go tool trace trace.out . | ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/go%20%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7.html#netpprof",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/go%20%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7.html#netpprof"
  },"2": {
    "doc": "Go 性能优化工具指南",
    "title": "go trace 分析步骤",
    "content": ". | trace 详细 | . | ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/go%20%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7.html#go-trace-%E5%88%86%E6%9E%90%E6%AD%A5%E9%AA%A4",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/go%20%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7.html#go-trace-分析步骤"
  },"3": {
    "doc": "Go 性能优化工具指南",
    "title": "dlv",
    "content": ". | 如何启动 . | dlv debug [main.go] | dlv attach [pid] [main.go] | dlv exec [binary] [–] [参数] | dlv test 格式：dlv test $packname example: dlv test . –test.run=\\^TestUpdateLocalImages$ | dlv core 举例: dlv core ./main ./core.8276 生成core dump: export GOTRACEBACK=crash 启动并调整core文件大小: ulimit -c unlimited core 文件是系统收到信号崩溃生成的文件 | . | 常用的调试命令 . | bt 查看栈 | frame [number] 跳入栈帧 | p 打印变量 | x 查看指定地址的变量值 | locals 查看函数局部变量值 | config -list 列出当前dlv配置 | config [配置项] [值] 设置dlv配置 | goroutines 列出当前协程 | goroutine [number] 切换协程 | . | . | ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/go%20%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7.html#dlv",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/go%20%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7.html#dlv"
  },"4": {
    "doc": "Go 性能优化工具指南",
    "title": "GODEBUG调试调度 《参考go语言编程之旅》",
    "content": ". | 调度调试 | . | ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/go%20%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7.html#godebug%E8%B0%83%E8%AF%95%E8%B0%83%E5%BA%A6-%E5%8F%82%E8%80%83go%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B%E4%B9%8B%E6%97%85",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/go%20%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7.html#godebug调试调度-参考go语言编程之旅"
  },"5": {
    "doc": "Go 性能优化工具指南",
    "title": "GODEBUG调试GC",
    "content": ". | GC调试 | . | ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/go%20%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7.html#godebug%E8%B0%83%E8%AF%95gc",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/go%20%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7.html#godebug调试gc"
  },"6": {
    "doc": "Go 性能优化工具指南",
    "title": "benchmark",
    "content": "go test -bench=. -benchmem -benchtime 0.1s -cpu 1,2,4 （#cpu 指定测试或基准测试的GOMAXPROCS值） go test -v -cpuprofile=prof.out -blockprofilerate n #每n纳打点记录一下 -coverprofile cover.out -memprofile mem.out -memprofilerate n #开启更精确的内存配置。如果为1， 将会记录所有内存分配到profile -mutexprofile mutex.out -mutexprofilefraction n -outputdir dir #在指定的目录放置输出文件 -trace trace.out . | . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/go%20%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7.html#benchmark",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/go%20%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7.html#benchmark"
  },"7": {
    "doc": "Go 性能优化工具指南",
    "title": "Go 性能优化工具指南",
    "content": "[toc] . | ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/go%20%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7.html",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/go%20%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7.html"
  },"8": {
    "doc": "gRPCurl 使用指南",
    "title": "1. 安装 gRPCurl",
    "content": "首先，您需要安装 gRPCurl。可以通过以下命令安装： . go install github.com/fullstorydev/grpcurl/cmd/grpcurl@latest . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#1-%E5%AE%89%E8%A3%85-grpcurl",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#1-安装-grpcurl"
  },"9": {
    "doc": "gRPCurl 使用指南",
    "title": "2. 列出服务",
    "content": "要列出服务器提供的所有服务： . grpcurl -plaintext localhost:50051 list . 这里，-plaintext 表示使用非加密连接，localhost:50051 是 gRPC 服务器的地址和端口。 . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#2-%E5%88%97%E5%87%BA%E6%9C%8D%E5%8A%A1",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#2-列出服务"
  },"10": {
    "doc": "gRPCurl 使用指南",
    "title": "3. 列出特定服务的方法",
    "content": "要列出特定服务的所有方法： . grpcurl -plaintext localhost:50051 list YourService . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#3-%E5%88%97%E5%87%BA%E7%89%B9%E5%AE%9A%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%96%B9%E6%B3%95",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#3-列出特定服务的方法"
  },"11": {
    "doc": "gRPCurl 使用指南",
    "title": "4. 描述服务或方法",
    "content": "要获取服务的详细描述： . grpcurl -plaintext localhost:50051 describe YourService . 要描述特定方法： . grpcurl -plaintext localhost:50051 describe YourService.YourMethod . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#4-%E6%8F%8F%E8%BF%B0%E6%9C%8D%E5%8A%A1%E6%88%96%E6%96%B9%E6%B3%95",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#4-描述服务或方法"
  },"12": {
    "doc": "gRPCurl 使用指南",
    "title": "5. 调用 gRPC 方法",
    "content": "grpcurl -plaintext -d '{\"field\": \"value\"}' localhost:50051 YourService/YourMethod . 这里，-d 后面跟着的是 JSON 格式的请求数据。 . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#5-%E8%B0%83%E7%94%A8-grpc-%E6%96%B9%E6%B3%95",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#5-调用-grpc-方法"
  },"13": {
    "doc": "gRPCurl 使用指南",
    "title": "6. 使用 TLS",
    "content": "如果服务器使用 TLS，移除 -plaintext 并添加适当的 TLS 选项： . grpcurl -cert /path/to/cert.pem -key /path/to/key.pem localhost:50051 YourService/YourMethod . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#6-%E4%BD%BF%E7%94%A8-tls",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#6-使用-tls"
  },"14": {
    "doc": "gRPCurl 使用指南",
    "title": "7. 使用 protoset 文件",
    "content": "如果服务器不支持反射，您可以使用 protoset 文件： . grpcurl -protoset /path/to/protoset.bin localhost:50051 YourService/YourMethod . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#7-%E4%BD%BF%E7%94%A8-protoset-%E6%96%87%E4%BB%B6",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#7-使用-protoset-文件"
  },"15": {
    "doc": "gRPCurl 使用指南",
    "title": "8. 流式 RPC",
    "content": "对于服务器流式 RPC： . grpcurl -plaintext -d '{\"field\": \"value\"}' localhost:50051 YourService/YourStreamingMethod . 对于客户端流式或双向流式 RPC，您可以使用 -d @ 从标准输入读取多个消息： . grpcurl -plaintext -d @ localhost:50051 YourService/YourClientStreamingMethod {\"message\": \"1\"} {\"message\": \"2\"} . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#8-%E6%B5%81%E5%BC%8F-rpc",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#8-流式-rpc"
  },"16": {
    "doc": "gRPCurl 使用指南",
    "title": "9. 设置元数据",
    "content": "要设置请求元数据： . grpcurl -H 'Authorization: Bearer token' -plaintext localhost:50051 YourService/YourMethod . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#9-%E8%AE%BE%E7%BD%AE%E5%85%83%E6%95%B0%E6%8D%AE",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#9-设置元数据"
  },"17": {
    "doc": "gRPCurl 使用指南",
    "title": "10. 格式化输出",
    "content": "使用 -format 选项来格式化输出： . grpcurl -plaintext -format json localhost:50051 YourService/YourMethod . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#10-%E6%A0%BC%E5%BC%8F%E5%8C%96%E8%BE%93%E5%87%BA",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#10-格式化输出"
  },"18": {
    "doc": "gRPCurl 使用指南",
    "title": "11. 显示详细信息",
    "content": "使用 -v 选项显示详细的请求和响应信息： . grpcurl -v -plaintext localhost:50051 YourService/YourMethod . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#11-%E6%98%BE%E7%A4%BA%E8%AF%A6%E7%BB%86%E4%BF%A1%E6%81%AF",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#11-显示详细信息"
  },"19": {
    "doc": "gRPCurl 使用指南",
    "title": "12. 设置超时",
    "content": "使用 -max-time 设置请求超时： . grpcurl -max-time 10s -plaintext localhost:50051 YourService/YourMethod . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#12-%E8%AE%BE%E7%BD%AE%E8%B6%85%E6%97%B6",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#12-设置超时"
  },"20": {
    "doc": "gRPCurl 使用指南",
    "title": "13. 使用环境变量",
    "content": "gRPCurl 支持通过环境变量设置某些选项，例如： . export GRPCURL_CERT=/path/to/cert.pem export GRPCURL_KEY=/path/to/key.pem grpcurl localhost:50051 YourService/YourMethod . | 使用配置文件 | . 您可以创建一个配置文件（例如 .grpcurl）来设置常用选项： . { \"plaintext\": true, \"max-time\": \"30s\", \"format\": \"json\" } . 然后使用 -config 选项： . grpcurl -config .grpcurl localhost:50051 YourService/YourMethod . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#13-%E4%BD%BF%E7%94%A8%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#13-使用环境变量"
  },"21": {
    "doc": "gRPCurl 使用指南",
    "title": "15. 服务器流式RPC",
    "content": "这个命令执行后，会持续输出服务器发送的所有响应 . grpcurl -d '{\"param\": \"value\"}' -plaintext localhost:50051 package.Service/StreamingMethod . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#15-%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%B5%81%E5%BC%8Frpc",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#15-服务器流式rpc"
  },"22": {
    "doc": "gRPCurl 使用指南",
    "title": "16. 客户端流式",
    "content": "这种方式grpcurl会等待在命令行行中输入多个json对象。每个对象用换行符分割。输入完成后按CTRL+D或CTRL+Z结束输入 . grpcurl -d @ -plaintext localhost:50051 package.Service/ClientStreamingMethod . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#16-%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%B5%81%E5%BC%8F",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#16-客户端流式"
  },"23": {
    "doc": "gRPCurl 使用指南",
    "title": "17. 双向流式rpc",
    "content": "grpcurl -d @ -plaintext localhost:50051 package.Service/BidirectionalStreamingMethod . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#17-%E5%8F%8C%E5%90%91%E6%B5%81%E5%BC%8Frpc",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html#17-双向流式rpc"
  },"24": {
    "doc": "gRPCurl 使用指南",
    "title": "gRPCurl 使用指南",
    "content": " ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/grpCurl.html"
  },"25": {
    "doc": "Home",
    "title": "Home",
    "content": " ",
    "url": "/",
    
    "relUrl": "/"
  },"26": {
    "doc": "效率工厂",
    "title": "效率工厂",
    "content": " ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/"
  },"27": {
    "doc": "架构设计",
    "title": "架构设计",
    "content": " ",
    "url": "/docs/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/",
    
    "relUrl": "/docs/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"
  },"28": {
    "doc": "打铁还需自身硬",
    "title": "打铁还需自身硬",
    "content": " ",
    "url": "/docs/%E6%89%93%E9%93%81%E8%BF%98%E9%9C%80%E8%87%AA%E8%BA%AB%E7%A1%AC/",
    
    "relUrl": "/docs/%E6%89%93%E9%93%81%E8%BF%98%E9%9C%80%E8%87%AA%E8%BA%AB%E7%A1%AC/"
  },"29": {
    "doc": "Vim 编辑器使用指南",
    "title": "Vim 编辑器使用指南",
    "content": "09/05/2023 10:01第一章 . / 正向查找 ? 反向查找 . dw 删除光标处到末尾的单词 . v 进入可视模式可以选中文本 . x 删除光标处的字符 . 重复上次操作 . dd 剪切一行 . G 增加当前行到末尾行的缩进层级 . a 当前光标后添加内容 . A 当前行末尾添加内容，$a的封装 . $ 移动到行尾 . s 删除光标处字符，进入插入模式 . f{char} 顺序查找char字符， ;跳到下一个 , 跳到上一个 . * 查找当前光标下的单词，节省输入了 . 第二章-普通模式 . db 删除从光标起到单词开头的内容 . b 移动到单词开头 . daw 删除光标处的单词，不要求光标必须在首尾 . &lt;C-a&gt; 对光标处数字执行+操作，直接输入会自动顺序找第一个数字 . &lt;C-x&gt; 对光标处数字执行-操作，直接输入会自动顺序找第一个数字 . yy 复制当前行 . p 粘贴 . set nrformats= Vim把所有数字都当成十进制处理，不管他们是不是0开头，（0开头容易当做八进制） . d2w 往后删除俩单词 . dl 删除光标处的字符 . dap 删除一整段 . gUaw 将光标处单词变成大写 . gUap 将整段都变成大写 . gUU 将一整行变成大写， uu小写 . g~ 翻转大小写 . &gt; 加缩进，&lt; 减缩进 . 6G 跳转到第六行 . 第三章-插入模式 . &lt;Esc&gt; 切换到普通模式 . &lt;C-[&gt; 切换到普通模式 . &lt;C-o&gt; 切换到插入-普通模式 . &lt;C-r&gt;{register} 从寄存器插入 . &lt;C-r&gt;= 进行表达式计算 . &lt;C-v&gt; {123}以十进制字符编码插入字符， u{1234}以十六进制字符编码插入字符 . R 进入替换模式，覆盖字符，重写, 一直替换 . r 进入替换模式，只覆盖一个字符，退出到普通模式 . gR 虚拟替换，tab不会被替换成单个字符，先填充tab之前空位 . u 撤销 . &lt;C-r&gt; 恢复撤销 . 第四章-可视模式 . viw 选中一个单词 . c 删除选中，进入插入模式 . v 可视化字符 . V 可视化一整行 . &lt;C-v&gt; 可视化一整列 . gv 重复上次选中的 . &lt;C-[&gt; 回到普通模式 . o 在可视模式下切换左右端点 . vit 高亮选中标签内部内容 . 第五章-命令行模式 . &lt;CR&gt; 回车 . &lt;C-w&gt; 在插入模式和命令行模式，删除到上一个单词的开头 . &lt;C-u&gt; 在插入模式和命令行模式，删除到行首 . :edit 读取文件 . :write 写入文件 . :tabnew 创建新标签页 . :split 分割窗口 . :prev/next 操作参数列表 . :bprev/bnext 操作缓存区列表 . :print 打印行, 缩写:p . :.,$ 当前行到末尾行 . :%s 文件中的所有行，等效于1,$ . :%s/A/B/g 将文件中所有的A替换成B，如果A中含有’/’，用%s#A#/g . :2 跳转到第2行，之后执行 :.,.+3p 相当于执行:2,5p . :copy 复制一行或多行，缩写:t . :[range]copy {address} . :6copy. 复制第6行到当前行的下一行，或写成6t. (t, copy To) . :t6 复制当前行到第6行的下一行 . :t. 复制当前行到当前行的下一行，类似yyp，但yyp会使用寄存器 . :move 移动一行或多行，缩写:m 另外一种写法dGp . :[range]move {address} . ‘&lt;,’&gt;m$ 将可视模式下选中的移动到文件尾部 . @: 重复上次的Ex命令 . :normal 在一系列连续行上执行一条普通模式命令，常与.命令配合使用 . :%noraml A; 在所有行尾添加; 完成之后回到普通模式 . :%normal i// 在所有行首添加//完成之后回到普通模式 . :bn(ext) 跳转到下一个缓存区 . :bp(revious) 跳转到上一个缓存区 . &lt;C-o&gt; 回到上一个位置，对于跳转的情况 . &lt;C-d&gt; 自动补全Ex命令 . &lt;Tab&gt; 自动补全，按多次每次出现一个候选项 . &lt;C-n&gt; 回溯历史，下一个候选项，替换上下键 . &lt;C-p&gt; 回溯历史，上一个候选项，替换上下键 . &lt;C-r&gt;&lt;C-w&gt; 复制光标下的单词并把它插入到命令行中 . &lt;C-r&gt;&lt;C-a&gt; 复制光标下的字符串并把它插入到命令行中 . q: 打开Ex命令历史记录，&lt;CR&gt;直接执行光标处的命令 . q/ 打开查找命令历史记录，&lt;CR&gt;直接执行光标处的命令 . &lt;C-f&gt; 从命令行模式打开Ex命令历史记录 . J 将下一行移动到当前行的末尾，会自动空格隔开 . :!ls 调用shell的ls命令 . :ls 调用Vim的内置命令，用来显示缓冲区列表的内容 . % Vim命令行中，%代表当前文件名 . :shell 启动一个交互式的shell，exit退出 . :read !{cmd} 把{cmd}命令的输出入读当前缓冲区中，如:read !pwd . :write !{cmd} 把缓冲区内容作为执行{cmd}的标准输入 . 2,$!sort -t’,’ -k2 . control+z 退出vim . fg 返回 . Tab . :tabnew [++opt选项] ［＋cmd］ 文件 建立对指定文件新的tab . :tabc 关闭当前的tab . :tabo 关闭所有其他的tab . :tabs 查看所有打开的tab . :tabp 前一个 . :tabn 后一个 . 标准模式下： . gt , gT 可以直接在tab之间切换。 . 更多可以查看帮助 :help table ， help -p . vimgrep . | :vimgrep /words/g % | copen 在当前的文件中查找　　　　==&gt; /words | . :vimgrep /words/j ** 当前目录下查找 . :vimgrep /words/ path/** 子目录查找 . :vimgrep /words/ path/*.c　　当前目录下的.c结 . :vimgrep /words/ path/*/.c 子目录查找.c结尾 . g: 表示是否把每一行的多个匹配结果都加入 . j:表示是否搜索完后定位到第一个匹配位置 . zc: 关闭折叠 . zo: 打开折叠 . za: 打开和关闭额折叠互相切换 . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/vim.html",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/vim.html"
  },"30": {
    "doc": "VirtualBox 使用指南",
    "title": "VirtualBox 使用指南",
    "content": ". | virtualbox 扩容根目录的方法 . | 管理-》虚拟介质磁盘 调整虚拟磁盘的大小 | 虚拟机linux中安装gparted工具进行分区合并 | . | virtualbox 搭建k8s集群 . | 加入节点： sudo kubeadm join 192.168.27.3:6443 –token hzauxd.h4x1jzrqofcqrhjn –discovery-token-ca-cert-hash sha256:63572ab9516ecd5a51f675a018d20d499c84a92ed2d39d34aa150944d3b3f7fe –apiserver-advertise-address 192.168.27.4 –node-name suohailong-ubuntu02 | 创建token: kubeadm token create | 查看加入命令 kubeadm token create –print-join-command –ttl 0 | 解决weave 在worker节点上失败 sudo ip route add 10.96.0.0/16 dev enp0s8 src 192.168.27.4 | 查看日志: journalctl -xefu kubelet | . | . ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/virtualbox.html",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/virtualbox.html"
  },"31": {
    "doc": "常用命令行工具集",
    "title": "常用命令行工具集",
    "content": "小工具 2. **docker 批处理命令** - **docker中 启动所有的容器命令** ``` docker start $(docker ps -a | awk '{ print $1}' | tail -n +2) ``` - **docker中    关闭所有的容器命令** ``` docker stop $(docker ps -a | awk '{ print $1}' | tail -n +2) ``` - **docker中 删除所有的容器命令** ``` docker rm $(docker ps -a | awk '{ print $1}' | tail -n +2) ``` - **docker中    删除所有的镜像** ``` docker rmi $(docker p_w_picpaths | awk '{print $3}' |tail -n +2) ``` 3. minikube ssh 方式启动k8s ```script minikube start --driver=ssh --native-ssh=false --ssh-user=suohailong --ssh-key=~/.ssh/id_rsa --ssh-ip-address=192.168.27.4 --image-mirror-country='cn' --registry-mirror=\"https://pp6nmizm.mirror.aliyuncs.com\" --alsologtostderr -v=4 --container-runtime=docker ``` 4. 其他 ```shell # 展示文件的elf格式 readelf --section-details --headers .output/opensnoop.bpf.o ``` 5. wsl ```shell # 安装 wsl install # 默认设置成用wsl2 wsl --set-default-version 2 # 进入wsl wsl ~ # 挂在共享目录 sudo mount -t drvfs '\\\\\\\\XTZJ-R5JK6L5HBR\\\\worker' ~/worker # 在windows中如何访问wsl的文件 资源管理器的地址栏中输入 \\\\wsl$ ``` 6. grep -o \"scanner--symantec\\[^ \\]\\*\" file 只输出搜索到的内容 ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/%E5%91%BD%E4%BB%A4.html",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/%E5%91%BD%E4%BB%A4.html"
  },"32": {
    "doc": "操作系统原理与实践",
    "title": "操作系统原理与实践",
    "content": "性能分析参考： [Perf-example](https://github.com/feiskyer/linux-perf-examples) ### 1. 进程管理 ##### 1. 进程的的状态： - R: 正在运行和等待运行的状态 - S: 可中断的睡眠状态 - D: 不可中断的睡眠状态 - Z: 僵死状态： 父进程没有等待子进程的结束就退出，导致子进程变为僵死进程 - T: 停止状态 疑问： 1. 可中断进程和不可中断进程存在哪里，运行进程存在哪里，他们是存储在一个数据结构里吗？ 答：可中断进程和不可中断进程存储在等待队列里，运行中的进程存储在就绪队列。就绪队列每个cpu都有一个。当进程需要等待某些事件时，被迫从就绪队列移除并加入到等待队列。当事件到达时，再从等待队列移入到就绪队列。 2. 可中断进程和不可中断进程的区别 答：可中断进程可以被信号唤醒，不可中断进程不会响应信号。 3. 僵尸进程是如何造成的，会有什么影响 答：进程退出，而父进程并没有调用wait函数等待。因为子进程退出释放资源和删除task\\_struct是分开的操作，通常子进程退出并不会立即删除task\\_struct。这样可有有机会让父进程获取并处理它的退出状态。进程的退出一定是调用了系统调用do\\_exit,这个函数会把和退出进程相关的资源都释放掉，比如：fd,mm\\_struct等，也会帮退出进程的子进程找好养父。 影响就是：大量的僵尸进程可能会用尽PID号，导致新进程不能创建 4. 进程表是什么？如何存储？ 答：linux中进程表就是由task\\_struct构成的双向列表，每个task\\_struct上存储有父进程指针和子进程的指针。 4. T状态是停止状态码？ 答：T状态是暂停状态或跟踪状态，造成这个状态的原因是进程收到了SIGTOP信号或者gdb调试进程时使用断点中断进程。 当进程收到SIGCONT信号后会恢复执行。 ##### 2. 进程的调度 1. 进程调度要解决什么问题？ 答：解决任务在考虑优先级的情况下，尽可能公平的利用cpu 1. 涉及到进程调度的数据结构都有什么？每个数据结构的作用 ![](../_resources/C6A90549-3DC0-46D9-8EC8-A7B57A93991E.png) 3. 进程调度的策略都有些。 答: 大的方面有两种策略：实时调度策略和普通调度策略， 分别对应的实时进程和普通进程。 实时策略中又具体细分了几种策略：FIFO， RR、DEADLINE 普通策略中也具体细分了几种策略: NORMAL、BATCH、IDLE 4. 操作系统如果实现这些调度策略 答：每个调度策略用一个类实现，比如1中fair_sched_class(完全公平调度算法)。每个cpu都有一个就绪队列，这个就绪队列由每个调度策略的就绪队列组合而成。每次调度，cpu都是按照优先级先选择一个调度策略，然后再从这个调度策略的就绪队列中找到下一个要运行的进程。 3. 调度器具体实现是什么？ 答：linux中调度器有俩种分别对应俩个实现函数，主动调度器实现函数为shedule, 周期性调度器实现函数为scheduler_tick 2. 进程检测need_resched标志执行调度的时机有哪些？ - 进程主动调用schedule - 从系统调用返回用户态时 - 当从中断返回用户态时 - 内核态启动可抢占 - 从中断返回内核态时 3. 内核通过检查need_resched标志来决定是否调用schedule函数，谁来设置这个标记? 答： - 周期性调度器，scheduler_tick会在当前进程时间片用尽时设置这个标记 - try_to_wake_up唤醒进程，当发现唤醒进程比当前进程更有资格运行时，则会设置这个标记。 - 进程主动要求调度的时候 4. 进程什么时候会主动要求调度 - 进程终止也就是调用exit() - 进程睡眠也就是调用sleep() - 调用系统调用sched_setscheduler改变调度策略 - 调用sched_yield放弃处理器 - 进程等待某个资源或事件 5. 进程什么时候睡眠，什么时候唤醒？ 答：等待I/O，等待被占用的信号量等。 6. 调度schedule都干什么？ - 寻找下一个合适的进程 - 执行上下文切换 7. 上下文切换是什么？ 答：就是把前一个任务的cpu寄存器和程序计数器等保存起来，然后加载新任务的上下文到cpu寄存器和程序计数器。 8. cpu 上下文切换的场景 - 进程上下文切换：从一个进程切换到另一个进程，除了保存进程的内核堆栈，寄存器等内核态数据，还需要保存进程的虚拟内存，栈，全局变量等用户空间的数据。 - 线程上下文切换: 线程切换分为两种情况，如果切换的线程分属两个进程，那上下文切换就是进程上下文切换，如果线程同属一个进程，那相较于进程上下文切换，在切换时可以保持虚拟内存等资源不动，只切换线程私有的数据、寄存器等。 - 中断上下文切换：中断上下文切换不涉及到进程的用户态，所以不需要保存进程的虚拟内存，全局变量等。只是保存中断服务程序执行所必须的装填，包括寄存器，内核堆栈，硬件中断参数等。 - 系统调用上下文切换: 系统调用的过程会执行俩次上下文切换，分别是用户态到内核态，内核态到用户态。 ##### 3. 系统中断 1. 软中断的实现方式是什么？ 答：软中断通常是以内核线程的方式运行，每个处理器有一个ksoftirqd/0 0为cpu编号。 2. 软中断在什么地方执行？ - 可以在中断处理程序返回之前，但必须不能超过2毫秒且最多执行10次， - 内核线程ksoftirq中， - 开启软中断的函数local_bh_enable。如果设置了CONFIG_IRQ_FORCE_THREADING所有软中断都必须在内核线程中完成 3. 系统中下半部机制都有哪些方式实现？ 答：工作队列，软中断，tasklet，等待队列，完成变量。 4. 工作队列，软中断，tasklet的区别和联系，分别用在什么场景？ - tasklet是基于软中断的，占用俩个软中断号：TASKLET_SOFTIRQ和HI_SOFTIRQ - 软中断是编译时静态定义的，在运行时不能添加和删除，tasklet可以在运行时添加和删除. - 同一种软中断的处理函数可以在多个处理器上执行，处理函数必须是可重入的需要使用锁来保护临界区。tasklet同一时刻只能运行在一个处理器上。 - 工作队列是使用内核线程(kworker)异步执行函数的通用机制。中断处理程序可以把耗时较长并且可能睡眠的函数交给工作队列来执行。 5. 软中断的优先级要高于用户进程吗？ 答：在中断上下文工作的软中断优先级高于普通进程。 6. 软中断事件频率过高会有什么影响？ 答：内核线程会因为cpu使用率过高而导致的软中断处理不及时，进而引发网络收发延迟，调度缓慢等。 ##### 4. cpu性能分析 2. 时钟节拍率，用户空间节拍率 分别是什么？如何查看和配置 - 时钟节拍率就是每秒中触发时间中断的次数，用全局变量jiffies来记录自系统自开机以来的节拍数。每发生一次时钟中断jiffies加一。节拍率可通过/boot/config来配置。 - 用户空间节拍率(USER_HZ)，是内核为方便用户空间而提供的。 固定为100也就是每秒100次。 /proc/stat提供的就是系统cpu和任务的统计信息，单位就是用户节拍率也就是10ms 3. 什么是进程组， 什么是会话？ 答： 进程组表示一组相互关联的进程， 会话是指共享同一个控制终端的一个或多个进程。 4. iowait 代表什么？ 答：iowait高表示cpu处于空闲状态，进程都在等io。 5. iowait高可能是什么问题？ 答：系统中只有I/O类型的进程在运行， 也可能是存在i/o性能瓶颈。 等待IO的进程一般是不可中断状态 6. cpu的状态 ![442f6a15d774444b1d27ff97b390463b.png](../_resources/442f6a15d774444b1d27ff97b390463b.png) 1. cpu 性能分析的工具都有哪些？分别有什么用 ![](../_resources/862FB328-9444-4647-8394-2A40D93D103A.png) ![](../_resources/7269CBE5-70EB-4B50-B4A7-C408D294B75D.png) ### 2. 内存管理 ##### 1. 系统内存管理结构： ![](../_resources/3C3D4D7F-5DD1-4DD1-BEBE-EB2265D1CCC3.png) 1. 解释上图 硬件上，内存管理单元（mmu) 用来做虚拟地址到物理地址的映射，页表缓存（TLB) 是页表的缓存。 内核中，页分配器采用伙伴算法 内核控制组是用来控制进程占用的内存资源 内存碎片整理是在找不到连续的物理页的时候通过迁移的方式整理内存得到连续的物理页 内存回收：不同的内存页有不同的回收策略。 块分配器指的是slab，主要用来分配一些内核通用的数据结构，比如task\\_struct， dentry cache等。通过kmalloc和kfree来分配释放 不连续页分配器指的是：通过vmalloc和vfree来分配释放的物理上不连续虚拟上连续的页 ##### 2. 内存管理全貌 ![](../_resources/4A34BFD4-ECC1-41DF-A6C9-A6499668103F.png) 1. 用户空间和内核空间分别是如何分配 ![](../_resources/47088698-68B4-4B5E-8090-92229F9CFCDF.png) 7. **伙伴算法是如何组织物理内存的** ![](../_resources/2A94986D-8BF3-4C2A-8EE6-DDCE3E8FC318.png) 每个zone 都有三个水位线 low min high。high是安全线，回收内存就是回收到安全线位置。内存位于low-min 说明内存轻微不足，内存位于low 以下说明内存严重不足。通过/proc/zoneinfo 可以查看这三个值 3. **内核什么时候回收内存** 异步回收。方式就是通过内核线程kswapd周期性回收。目的就保证系统任何时刻都能为内存申请提供足够的内存。 触发时机：当申请内存时发现内存处于low-min之间，触发异步回收 当申请大于空闲时强制回收。当申请内存时发现内存处于low以下则直接回收。 4. **那些内存会被回收呢？** 一种是anon的匿名页，主要回收手段就是swap, 一种是file-backed文件映射页，主要回收手段是写回和清空 内存和文件缓存一共用了四条链表组织 匿名页inactive, active, 文件页inactive, active 手动回收，主要是回收page cache, slab cache中的可回收部分。 可以通过写入/proc/sys/vm/drop_cache 1,2,3. 来控制删除page cache, slab cache和都删除。 3. **进程虚拟空间是如何组织的** ![](../_resources/304B06F4-1FCA-413D-BE69-F7D9E67675DC.png) ![](../_resources/A6F0091F-99C8-4B31-A0B3-09A57A61E428.png) 每个段在内核中都是由一个vm_area_struct构成 4. **进程和内核页表分别存在什么地方** 进程的页表目录存储在mm_stuct-pgd 内核的页表存储在0号内核线程的active-mm-ini_mm-pgd ![](../_resources/27963A19-4F66-458F-83FC-C730A48F4FE5.png) 页表存储在物理内存的，但是起作用的时候，页表必须加载到mmu 5. **Linux的内存回收算法用的什么？** LRU 6. **内存映射都有哪几种方式，分别有什么意义？** 文件映射：把文件指定区间的内容读到物理页，再把物理页映射到虚拟内存空间。(通常是指有设备支撑） 匿名映射：就是把物理页映射到用户的虚拟内存空间 7. **进程什么时候被oom** 页分配器在多次尝试直接回收失败以后，就会调用oom killer杀死进程。可以通过配置来改变进程的oom值降低被杀的风险。 8. **buffer cache SReclaimable 分别是什么？有什么作用？** buffer: 内核缓冲区用到的内存, 对原始磁盘块的临时存储。 cache: 内核文件页缓存和Slab用到的内存，对应的是/proc/meminfo中Cached（用来缓存从文件读取的数据）和Sreclaimable之和 SReclaimable: 可回收的slab, 就是指在调用Kmem_cache_create函数向slab分配器申请内存时，使用SLAB_RECLAIM_ACCOUNT标志。主要包括dentry cache, inode cache等各种用slab分配器创建的各种缓存。 9. **如何衡量缓存使用的好坏** 缓存命中率， 通过缓存获取到数据的请求次数/数据请求的总次数 10. **缓存相关工具** cachestat 查看整个操作系统的读写命中情况 cachetop 查看每个进程的缓存命中情况 pcstat 查看指定文件在内存中的缓存大小 dd 命令磁盘和文件的拷贝工具，经常用来测试磁盘和文件的读写性能。 memleak 查看内存泄露 pmap 查看进程的内存分布 11. **很多情况下明明发现Swap升高，但系统剩余内存还很多，这是为什么？** 这是因为NUMA 架构下,多个处理器被划分到了不同的Node上。每个Node有自己的本地管理空间. ![](../_resources/4B05CFCA-DF7D-41B2-9C06-5E37BF8874A5.png) 某个Node的内存不足时，就会导致本Node的内存回收，进行swap, 当然可以通过设置/proc/sys/vm/zone_reclaim_mode ,来进行选择当本地Node内存不足时是从其他Node上寻找空闲内存还是从本地回收。 12. **为什么匿名页要用swap的方式回收？** 因为是堆内存或者是mmap分配的共享内存，它们很可能还要再次访问，所以不能直接回收。 13. **如何设置能影响回收策略** /proc/sys/vm/min_free_kbytes 调整系统定期回收内存的阈值 /proc/sys/vm/swappiness 调整文件页和匿名页的回收倾向 /proc/sys/vm/zone_reclaim_mode 调整NUMA本地回收策略。 14. **Swap 有两种类型** - Swap 分区 - Swap 文件 15. **开启文件swap流程** - 创建swap文件 - 配置swap文件：mkswap [文件名] - 开启swap: swapon [文件名] - 关闭swap: swapoff 16. **如何查查看swap影响的进程** cachetop smem --sort swap 将进程按swap得使用量排序 17. **内存性能指标** ![](../_resources/041504D8-8C36-4213-9C9F-67BEC5292176.png) 主缺页异常: 缺页异常需要磁盘I/O的介入 次缺页异常: 可以直接从物理内存分配 可用内存：包括剩余内存和可回收缓存 共享内存：共享内存是通过tmpfs实现的,包括真实的共享内存和动态链接库以及程序的代码段。 18. **内存指标对应的工具** ![](../_resources/BF8C3365-6C96-4684-98E5-6C2D9BE731C4.png) 3. **内存分析流程** ![](../_resources/71C4BE13-E19E-4B73-A58E-75DEC82DF476.png) 4. **裸IO 直接IO和缓存IO** 缓存IO：io请求会进过文件系统页缓存，这样的方式读取数据会经过两次数据拷贝，一次是从设备拷贝到内核，一次是从内核拷贝的用户缓存 裸Io和直接Io 直接IO就是绕过文件系统页缓存，直接和设备通用层打交道。数据只会经过一次拷贝，从内核到用户缓存。 裸IO是直接访问/dev下的块设备，绕过了整个文件系统。裸IO和直接IO的应用场景都是用在应用程序有自己的缓存，追求性能最大化。比如数据库服务。 ### 3.文件系统/IO管理 #### 1.系统文件系统的架构： ![a6668a8f3128e5f0331ea6efe88043c1.png](../_resources/a6668a8f3128e5f0331ea6efe88043c1.png) IO读写流程： 1. 应用程序通过系统调用(Read/Write)发起I/O请求 2. 系统调用处理：系统调用接口在接受到请求后，将请求转换为内核能理解的格式，然后调用对应的内核函数（这里涉及用户空间到内核空间的切换） 3. 内核处理：在内核中， 对于读操作，内核首先检查所请求的数据是否在页缓存中， 如果在，则拷贝数据到用户空间，如果不在则交给文件系统处理。 对于写请求，同样写写入页缓存，稍后交给文件系统写入磁盘。 4. 文件系统处理：对于涉及到文件I/O的请求，内核会调用文件系统函数来处理， 文件系统会根据文件系统的类型和布局，将请求转换为对应的磁盘块操作。比如一次磁盘操作的磁盘块为4K, 一个请求读1MB的数据，那么这里会将该请求转换为125次磁盘操作。 5. 设备驱动处理：转换好的磁盘操作会交给设备驱动的I/O读写队列。 I/O调度器跟进调度算法从I/O读写队列中获取任务，进行实际的磁盘读写。 6. 中断和完成：当硬件完成操作后，它会通过中断通知cpu，然后设备驱动会处理这个中断，更新对应的内核数据结构（如果一个读操作完成了，数据会被从硬件（比如说硬盘）复制到内核空间的缓冲区中，然后再复制到页缓存。此外，对于写操作，一旦数据成功写入硬盘，对应的页缓存中的数据会被标记为 \"clean\"，表示它们与磁盘上的数据是一致的。）。然后唤醒之前因为等待I/O完成而被阻塞的进程。 7. 应用程序接收结果：对于 read 操作，数据现在在应用程序指定的缓冲区中。对于 write 操作，应用程序被通知操作已经完成。 ##### 2. 系统文件系统的相关问题 1. **虚拟文件系统的数据结构有哪些，分别是什么作用?** **超级块**：存储整个文件系统的信息，比如文件系统的类型等。当把文件系统挂载到内存目录树时就会读取文件系统的超级块。 **挂载描述符(mount)** ：用来描述一个文件的挂载实例 **文件类型(file_system_type)**: 这结构用来描述每种文件系统的类型，并实现了mount方法用来读取和解析这个类型的超级块。 **inode**: 用来记录文件的元数据，文件大小，访问权限，数据位置等。 **dentry**: 对应目录里的一条记录，记录文件名字和inode的对应关系，类似于file:inode。目录项是由内核维护的一个内存数据结够。 内核里专门有哥目录项缓存用来缓存dentry **struct file**结构体：代表一个打开的文件实例 **struct file_struct**: 代表打开的文件描述符表 8. **如何通过挂载实例访问挂载到的文件系统。** 3. **进程如何和文件关联的** ![](../_resources/B3F22A46-7D7F-445E-B215-EAE896D532A6.png) 4. **硬链接和软连接的区别** 5. **目录项和inode的关系** ![](../_resources/64D7BC71-0BB7-433C-810A-32C55C0B3FA1.png) 假设有一个文件 /home/user/document.txt，进程需要打开并读取该文件： 1. 打开文件： 1. 进程调用 open(\"/home/user/document.txt\", O_RDONLY)。操作系统在 /home/user 目录中查找 document.txt 的目录项，获取指向 inode 的指针。 2. 操作系统通过目录项中的指针加载 document.txt 的 inode，获取文件的元数据。 3. 操作系统在系统打开文件表中创建一个新的条目，记录文件的状态信息（如读模式）和指向 inode 的指针。 4. 操作系统在进程的文件描述符表中创建一个新的条目，包含文件描述符（假设为 3）和指向系统打开文件表的指针。 2. 读取文件： 1. 进程调用 read(3, buffer, size)。 2. 操作系统通过文件描述符 3 在进程的文件描述符表中找到对应的条目，获取指向系统打开文件表的指针。 3. 操作系统在系统打开文件表中找到对应的条目，获取文件的状态信息和指向 inode 的指针。 4. 操作系统通过 inode 获取文件的数据块指针，读取相应的数据块并将数据复制到进程的缓冲区 buffer 中。 5. **目录项缓存，inode缓存，页缓存的作用**？ 假设有一个文件 /home/user/document.txt，进程需要打开并读取该文件： 1. 路径解析： 操作系统首先在目录项缓存中查找 /home、/home/user 和 /home/user/document.txt 的目录项。如果缓存中存在这些目录项，则可以快速解析路径，找到对应的 inode 指针。如果目录项缓存中没有这些目录项，则需要访问磁盘上的目录结构，生成目录项并缓存起来。 2. 加载 inode： 操作系统通过目录项中的指针在 inode 缓存中查找 document.txt 的 inode。如果缓存中存在该 inode，则可以快速获取文件的元数据。如果 inode 缓存中没有该 inode，则需要访问磁盘上的 inode 结构，加载 inode 并缓存起来。 3. 读取文件数据： 操作系统通过 inode 中的数据块指针在页缓存中查找 document.txt 的数据块。如果缓存中存在这些数据块，则可以快速读取文件数据。如果页缓存中没有这些数据块，则需要从磁盘读取数据块，并将其缓存起来。 1. **linux io读写流程** ![](../_resources/E2A02941-3219-4C6A-A30E-2F383D4BCE25.png) 直接io: 读：从块设备层直接拷贝数据到用户态。 写：直接从用户态拷贝数据到块设备 缓存io: 读：从块设备层拷贝到内核页缓存，从内核页缓存在拷贝到用户态。 写：从用户态拷贝数据到内核页缓存，并设置页为脏，真正的写由timer触发内核线程去写 2. **直接io mmap 缓存io？** ![](../_resources/截屏2021-07-04%20上午1.24.01.png) 3. **通用块层的作用？** - 统一各种异构的磁盘设备，向上为文件系统和应用程序，提供访问设备的标准接口。 - 对io请求进行调度排队，通过重新排序和请求和并的方式提高磁盘读写效率。 10. **io调度的算法都有哪些？** - NOOP 先入先出 常用于SSD - CFQ 完全公平调度器，为每个进程维护一个I/O调度队列，并按照时间片来均匀分配每个进程的I/o请求. 适用于运行大量进程的系统。 - Deadline 分别为读写请求创建不同的io队列，并确保最终期限的请求优先处理。 多用于I/O压力比较重的场景, 比如数据库。 11. **如何实现零拷贝?** 用户态直接io mmap+write sendfile(系统调用） sendfile + DMA gather copy splice 12. **内核刷新赃页的逻辑？** - 内核周期性的通过内核线程pdflush检测页缓存中的脏页然后与设备进行同步。 - 当内存紧张时被动触发pdflush写回赃页 - 有专门的系统调用sync可由用户应用程序控制回收 13. **实现页缓存的数据结构是什么？** 基数树(key和value的映射) ，基数树是针对稀疏的长整型key数据的查找，这种数据用哈希表存储的话哈希函数难以设计。 14. **块缓存的作用是什么？实现块缓存的数据结构是什么？** 块缓存就是块在内存的映射，快缓存在内核中的数据结构由缓存区头(buffer_head)和有用数据两部分组成。如下图![](../_resources/截屏2021-07-03%20下午10.26.03.png) 图中一页划分成了4个块，由4个缓存区头描述。页缓存也可能指向数据页。 15. **块缓存和页缓存的区别和联系** 块缓存和页缓存指向同样的页，块缓存可分为独立部分和附加部分，独立部分用来支持以块为单位的操作，附加部分用来在回写数据时减小回写的粒度。因为一次同步可能只需要同步脏的部分不需要同步整个页。页缓存用来支持以页为单位的块设备操作。 16. **同步IO，异步IO，阻塞IO和非阻塞IO的区别和联系** 同步IO指的是系统接收到io请求后等到处理完成后才会响应 异步指的是系统收到io请求后系统会先告诉应用程序请求已收到，之后处理完成后再以事件的方式告知应用程序 阻塞io指的是应用程序在提交io请求后一直等待直到结果返回 非阻塞io指的是应用程序在提交io请求后不等待，可以去处理其他任务。 17. **磁盘和文件系统的性能指标?** ![](../_resources/DF8E4F54-1E40-43A3-B7CC-972AAED122E4.png) 18. **io性能分析的一般思路** - 先用top vmstat观察资源整体情况 - 在用iostat具体分析磁盘问题 - 用pidstat定位具体进程的io问题 - 用strace lsof定位具体操作和文件 ![](../_resources/E0035DA2-F5AB-419A-ADF0-AF367504FD3A.png) 19. **磁盘性能分析的工具** ![](../_resources/51F5ABE4-75CA-4BF9-885B-E6D222FEAEBB.png) 17. **如何优化磁盘io?** - 第一步进行io基准测试，找出优化目标，对应的工具有fio(可以用来测试io),blktrace(记录磁盘设备的io访问情况）。 - 第二步找到性能瓶颈 - 第三部确定优化方案 22. IO性能优化的基本思路？ 1. 应用程序优化 1. - 尽量采用追加写 2. - 尽量采用缓存io 3. - 可以在应用内部构建自己的缓存,或者用redis这类外部缓存 4. - 对同一块磁盘反复读写可以采用mmap的方式代替read/write 5. - 在使用 CFQ 调度器时，可以用 ionice 来调整进程的 I/O 调度优先级 6. - 在多个应用程序共享相同磁盘时，为了保证 I/O 不被某个应用完全占用，推荐你使用 cgroups 的 I/O 子系统，来限制进程 / 进程组的 IOPS 以及吞吐量 7. 在需要同步写的场景中，尽量将写请求合并，而不是让每个请求都同步写入磁盘，即可以用 fsync() 取代 O_SYNC 1. 文件系统优化 1. - 可以根据不同的负载场景选择不同的文件系统 2. - 在选好文件系统后，还可以进一步优化文件系统的配置选项，包括文件系统的特性（如ext_attr、dir_index）、日志模式（如journal、ordered、writeback）、挂载选项（如 noatime）等等 3. - 可以优化文件系统的缓存。比如，你可以优化 pdflush 脏页的刷新频率（比如设置 dirty_expire_centisecs 和dirty_writeback_centisecs）以及脏页的限额（比如调整 dirty_background_ratio 和 dirty_ratio 等）。再如，你还可以优化内核回收目录项缓存和索引节点缓存的倾向，即调整 vfs_cache_pressure（/proc/sys/vm/vfs_cache_pressure，默认值 100），数值越大，就表示越容易回收。最后，在不需要持久化时，你还可以用内存文件系统 tmpfs，以获得更好的 I/O 性能 。tmpfs 把数据直接保存在内存中，而不是磁盘中。比如 /dev/shm/ ，就是大多数 Linux 默认配置的一个内存文件系统，它的大小默认为总内存的一半。 2. 磁盘优化 - 最简单有效的优化方法，就是换用性能更好的磁盘，比如用 SSD 替代 HDD - 我们可以使用 RAID，把多块磁盘组合成一个逻辑磁盘，构成冗余独立磁盘阵列 - 针对磁盘和应用程序 I/O 模式的特征，我们可以选择最适合的 I/O 调度算法 - 我们可以对应用程序的数据，进行磁盘级别的隔离。比如，我们可以为日志、数据库等 I/O 压力比较重的应用，配置单独的磁盘。 - 在顺序读比较多的场景中，我们可以增大磁盘的预读数据 - 我们可以优化内核块设备 I/O的选项。比如，可以调整磁盘队列的长度/sys/block/sdb/queue/nr_requests，适当增大队列长度，可以提升磁盘的吞吐量（当然也会导致I/O 延迟增大）。 18. **为什么说建立应用自己的缓存有其一定的必要性？** 因为多个程序共用系统缓存，可能存在问题，万一有的应用程序清除缓存就可能影响到其他程序。 ",
    "url": "/docs/%E6%89%93%E9%93%81%E8%BF%98%E9%9C%80%E8%87%AA%E8%BA%AB%E7%A1%AC/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html",
    
    "relUrl": "/docs/%E6%89%93%E9%93%81%E8%BF%98%E9%9C%80%E8%87%AA%E8%BA%AB%E7%A1%AC/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html"
  },"33": {
    "doc": "数据库选型指南",
    "title": "数据库选型指南",
    "content": "# 数据库选型决策总结 # 主从复制数据库总结 ## 1. MySQL - **选主方式：** 手动选主。 - **故障转移方式：** 手动故障转移。自动故障转移需要额外的组件 - **是否支持读写分离：** 支持。 - **主从一致性实现：** 异步复制 / 半同步复制。 ## 2. PostgreSQL - **选主方式：** 手动选主。 - **故障转移方式：** 手动故障转移。自动故障转移需要额外的组件 - **是否支持读写分离：** 支持。 - **主从一致性实现：** 异步复制 / 同步复制。 ## 3. MongoDB - **选主方式：** 自动选主（Raft 协议）。主节点保存所有副本信息 - **故障转移方式：** 自动故障转移（Raft 协议）。 - **是否支持读写分离：** 支持。 - **主从一致性实现：** 最终一致性 / 写关注（Write Concern）。 ## 4. Redis（单机模式） - **选主方式：** 手动选主。 - **故障转移方式：** 手动故障转移。 - **是否支持读写分离：** 支持。 - **主从一致性实现：** 异步复制。 ## 5. Redis（Sentinel 模式） - **选主方式：** 自动选主（Sentinel 选举）。sentinel掌握主节点和副本的信息 - **故障转移方式：** 自动故障转移（Sentinel 选举）。 - **是否支持读写分离：** 支持。 - **主从一致性实现：** 异步复制。 ## 6. Redis（Cluster 模式） - **选主方式：** 自动选主（Gossip + 选举）。 - **故障转移方式：** 自动故障转移（Gossip + 选举）。 - **是否支持读写分离：** 支持。 - **主从一致性实现：** 异步复制 / 可配置写一致性级别。 ## 7. Elasticsearch - **选主方式：** 自动选主（类 Raft 协议）。主分片掌握副本信息 - **故障转移方式：** 自动故障转移（类 Raft 协议）。 - **是否支持读写分离：** 支持。 - **主从一致性实现：** 最终一致性 / 写一致性级别。 ## 8. InfluxDB - **选主方式：** 自动选主（Raft 协议）。 - **故障转移方式：** 自动故障转移（Raft 协议）。 - **是否支持读写分离：** 支持。 - **主从一致性实现：** 最终一致性 / 写一致性级别。 ## 9. Amazon Aurora - **选主方式：** 自动选主（Quorum 协议）。 - **故障转移方式：** 自动故障转移（Quorum 协议）。 - **是否支持读写分离：** 支持。 - **主从一致性实现：** 强一致性。 --- # 总结表格 | 数据库名 | 选主方式 | 故障转移方式 | 是否支持读写分离 | 主从一致性实现 |------------------|------------------------------|----------------------------|------------------|------------------------------------| **MySQL** | 手动 | 手动 | 支持 | 异步复制 / 半同步复制 | **PostgreSQL** | 手动 | 手动 | 支持 | 异步复制 / 同步复制 | **MongoDB** | 自动（Raft） | 自动（Raft） | 支持 | 最终一致性 / 写关注 | **Redis（单机）**| 手动 | 手动 | 支持 | 异步复制 | **Redis（Sentinel）**| 自动（Sentinel） | 自动（Sentinel） | 支持 | 异步复制 | **Redis（Cluster）**| 自动（Gossip + 选举） | 自动（Gossip + 选举） | 支持 | 异步复制 / 可配置写一致性级别 | **Elasticsearch**| 自动（类 Raft） | 自动（类 Raft） | 支持 | 最终一致性 / 写一致性级别 | **InfluxDB** | 自动（Raft） | 自动（Raft） | 支持 | 最终一致性 / 写一致性级别 | **Amazon Aurora**| 自动（Quorum） | 自动（Quorum） | 支持 | 强一致性 | # 无主复制数据库总结 ## 1. Cassandra - **核心特点：** - 分布式列族数据库，适合高并发写入和大规模数据存储。 - **复制方式：** - 无主复制，数据通过一致性哈希分布到多个节点。 - 每个节点对等，没有主从之分。 - **一致性机制：** - 使用 **Quorum** 机制确保数据一致性。 - 支持灵活的读写一致性级别（如 ONE、QUORUM、ALL）。 - **适用场景：** - 高并发写入场景，如日志存储、时间序列数据。 ## 2. DynamoDB - **核心特点：** - 分布式键值数据库，由 AWS 提供，支持高可用性和弹性扩展。 - **复制方式：** - 无主复制，数据通过一致性哈希分布到多个节点。 - 每个节点对等，没有主从之分。 - **一致性机制：** - 支持 **强一致性** 和 **最终一致性** 两种模式。 - 使用 Quorum 机制确保数据一致性。 - **适用场景：** - 需要高可用性和弹性扩展的场景，如电商、游戏。 ## 3. Riak - **核心特点：** - 分布式键值数据库，适合高可用性和灵活的一致性配置。 - **复制方式：** - 无主复制，数据通过一致性哈希分布到多个节点。 - 每个节点对等，没有主从之分。 - **一致性机制：** - 使用 **Quorum** 机制确保数据一致性。 - 支持灵活的读写一致性级别（如 ONE、QUORUM、ALL）。 - **适用场景：** - 高可用性场景，如分布式缓存、会话存储。 ## 4. Voldemort - **核心特点：** - 分布式键值数据库，由 LinkedIn 开发，适合大规模数据存储。 - **复制方式：** - 无主复制，数据通过一致性哈希分布到多个节点。 - 每个节点对等，没有主从之分。 - **一致性机制：** - 使用 **Quorum** 机制确保数据一致性。 - 支持灵活的读写一致性级别（如 ONE、QUORUM、ALL）。 - **适用场景：** - 大规模数据存储场景，如分布式缓存、推荐系统。 ## 5. ScyllaDB - **核心特点：** - 高性能分布式列族数据库，兼容 Cassandra API。 - **复制方式：** - 无主复制，数据通过一致性哈希分布到多个节点。 - 每个节点对等，没有主从之分。 - **一致性机制：** - 使用 **Quorum** 机制确保数据一致性。 - 支持灵活的读写一致性级别（如 ONE、QUORUM、ALL）。 - **适用场景：** - 高性能、低延迟场景，如实时数据分析、物联网。 --- # 总结表格 | 数据库名 | 核心特点 | 复制方式 | 一致性机制 | 适用场景 |------------------|------------------------------|----------------|------------------|--------------------------------------------| **Cassandra** | 分布式列族数据库 | 无主复制 | Quorum | 高并发写入，日志存储，时间序列数据 | **DynamoDB** | 分布式键值数据库 | 无主复制 | Quorum | 高可用性，弹性扩展，电商，游戏 | **Riak** | 分布式键值数据库 | 无主复制 | Quorum | 高可用性，分布式缓存，会话存储 | **Voldemort** | 分布式键值数据库 | 无主复制 | Quorum | 大规模数据存储，分布式缓存，推荐系统 | **ScyllaDB** | 高性能分布式列族数据库 | 无主复制 | Quorum | 高性能，低延迟，实时数据分析，物联网 | ## 1. 电商系统的订单管理 **场景需求：** - 存储订单信息（订单ID、用户ID、商品ID、数量、价格、状态等）。 - 支持高并发下单（每秒数千次请求）。 - 支持复杂的查询（如按用户ID查询订单、按状态查询订单）。 **选型决策：** - **推荐数据库：** 关系型数据库（如 MySQL、PostgreSQL）。 - **理由：** - 需要支持复杂查询和事务（如订单创建、库存扣减）。 - 关系型数据库的 ACID 事务和 SQL 查询功能非常适合此类场景。 - 可以通过分库分表和缓存（如 Redis）提升性能。 ## 2. 社交网络的用户动态 **场景需求：** - 存储用户发布的动态（动态ID、用户ID、内容、发布时间等）。 - 支持高并发写入（每秒数万次请求）。 - 支持按时间线查询用户动态。 **选型决策：** - **推荐数据库：** NoSQL 数据库（如 Cassandra、MongoDB）。 - **理由：** - 高并发写入需求，NoSQL 数据库的分布式架构和水平扩展能力非常适合。 - 用户动态不需要强一致性，最终一致性模型足够。 - 按时间线查询可以通过时间戳索引优化。 ## 3. 实时日志分析系统 **场景需求：** - 存储海量日志数据（日志ID、时间戳、日志内容等）。 - 支持高吞吐写入（每秒数十万条日志）。 - 支持实时查询和聚合分析（如按时间范围查询日志）。 **选型决策：** - **推荐数据库：** NoSQL 数据库（如 Elasticsearch、Cassandra）。 - **理由：** - 高吞吐写入需求，NoSQL 数据库的分布式架构和写入优化能力非常适合。 - Elasticsearch 支持实时查询和全文搜索，适合日志分析场景。 - 如果需要更高的写入性能，可以选择 Cassandra。 ## 4. 内容管理系统的文章存储 **场景需求：** - 存储文章内容（文章ID、标题、内容、作者、发布时间等）。 - 支持全文搜索（如按关键词搜索文章）。 - 支持复杂的查询（如按作者、发布时间筛选文章）。 **选型决策：** - **推荐数据库：** Elasticsearch。 - **理由：** - Elasticsearch 是一个高效的全文搜索引擎，支持复杂的查询和聚合分析。 - 适合存储非结构化或半结构化的文章数据。 - 如果需要事务支持，可以结合关系型数据库（如 MySQL）使用。 ## 5. 物联网设备数据存储 **场景需求：** - 存储设备上报的数据（设备ID、时间戳、传感器数据等）。 - 支持高并发写入（每秒数十万条数据）。 - 支持按时间范围查询设备数据。 **选型决策：** - **推荐数据库：** 时序数据库（如 InfluxDB、TimescaleDB）。 - **理由：** - 时序数据库专门设计用于存储和查询时间序列数据，适合物联网设备数据存储场景。 - 支持高吞吐写入和高效的时间范围查询。 - 数据压缩功能可以减少存储空间占用。 ## 总结 | 场景 | 推荐数据库 | 核心理由 |--------------------------|--------------------------|--------------------------------------------| 电商系统的订单管理 | 关系型数据库（MySQL） | 复杂查询、事务支持、ACID 特性。 | 社交网络的用户动态 | NoSQL 数据库（Cassandra）| 高并发写入、低一致性要求、时间线查询。 | 实时日志分析系统 | NoSQL 数据库（Elasticsearch）| 高吞吐写入、实时查询、全文搜索。 | 内容管理系统的文章存储 | Elasticsearch | 全文搜索、复杂查询、灵活的数据模型。 | 物联网设备数据存储 | 时序数据库（InfluxDB） | 高并发写入、时间序列数据存储、高效时间范围查询。 | ```mermaid graph TD A[事务需求] --> B{ACID完整支持?} B -->|是| C[关系型数据库] B -->|否| D{最终一致性容忍?} D -->|是| E[分布式NoSQL] D -->|否| F[NewSQL] C --> G[强事务: Oracle/MySQL] F --> H[分布式事务: TiDB] E --> I[文档: MongoDB] E --> J[列存: Cassandra] style C fill:#f9d5e5 style F fill:#d5e8d4 style E fill:#e2d5e7 ``` ```mermaid graph TD A{是否需要高吞吐?} -->|是| B{是否需要持久化存储?} A -->|否| C{是否需要复杂路由?} B -->|是| D[Kafka] B -->|否| E[NSQ] C -->|是| F[RabbitMQ] C -->|否| G{是否需要事务消息?} G -->|是| H[RocketMQ] G -->|否| I[Redis Stream] style D fill:#f0b27a style F fill:#a9dfbf style H fill:#f9e79f style I fill:#d7bde2 ``` ",
    "url": "/docs/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E6%95%B0%E6%8D%AE%E5%BA%93%E9%80%89%E5%9E%8B.html",
    
    "relUrl": "/docs/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E6%95%B0%E6%8D%AE%E5%BA%93%E9%80%89%E5%9E%8B.html"
  },"34": {
    "doc": "系统架构设计方法论",
    "title": "系统架构设计方法论",
    "content": "[toc] # 一、 系统设计步骤 ## 1. 需求分类 ### 2. 功能需求 ### 3. 质量需求 1. 质量需求为**功能需求**提供了质量度量，也直接决定了架构。 2. 质量属性不仅是满足客户的质量要求，是需要满足所有利益相关者的质量要求，比如开发人员，运维人员。 3. 质量属性必须是可测试和可测量的 4. 必须权衡以保证我们选择正确的质量属性（某些质量属性是互相矛盾的） 5. 考虑质量属性的可行性， 以确保我们可以兑现我们的承诺 ### 4. 约束(技术限制,业务限制,法律限制) ## 2. API设计 ## 3. 先设计一个适应功能需求的架构 ## 4. 优化架构以满足质量需求 ",
    "url": "/docs/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95%E8%AE%BA.html",
    
    "relUrl": "/docs/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95%E8%AE%BA.html"
  },"35": {
    "doc": "计算机网络原理与实践",
    "title": "计算机网络原理与实践",
    "content": "网络编程参考：[代码用例](https://hub.fastgit.org/froghui/yolanda.git) # 1. 网络协议 ## 1. 二层协议 1. 二层协议主要解决哪些问题？ - 帧的源头及目的地（通过mac头标明接收方和发送方) - 发送帧的规则 1. 轮流协议：多个发送放轮流发送 2. 信道划分：多个发送方往不通的信道发送 3. 随机接入协议：多个发送放随机发送。 - 如何纠正发送错误 通过在帧的最后加入crc校验码检验数据错误。 1. 二层帧的传送格式 ![](../_resources/406CB9DF-4691-481B-B4B2-2D04D09FEDF6.jpg) 2. 二层硬件设备 交换机 3. 交换机如何构建拓扑结构？ 广播+学习， 每次通过包发送接口记录来源到mac地址到转发表，当所有接口都发送过一次数据后转发表也就补充完整了。 4. 交换机的环路如何解决？ STP 协议，原理就是最小生成树 5. 什么是vlan? 有什么用 vlan是用来实现虚拟局域网的，具体实现原理就是在二层协议头加一个tag，用来区分该帧属于哪个虚拟网络，只有tag相同的才会互相转发。 ![](../_resources/06B46DF9-DF61-4AFE-9418-46A70178FA2F.jpg) 6. 支持Vlan的交换机互相是通过什么口连接的 Trunk口，它可以转发属于任何vlan的包。 7. ARP协议有什么作用？ 通过ip地址得到mac地址，帧格式如下 ![](../_resources/01D56035-C9A2-4FCB-BE0D-5AD296656B93.jpg) ARP协议是通过向局域网内广播ARP格式的包得到对应ip的mac地址。 ## 2. 三层协议 1. icmp 协议的作用是什么？ 侦测当前网络状况 2. icmp的实现有哪些？ ping: 实现了icmp的查询报文 Traceroute：实现了icmp的差错报文 3. ip协议格式 ![](../_resources/D362B947-9FC5-4D6C-BF40-BBAE70AB8EF6.jpg) mac头中的16位协议类型标明上层协议是什么类型 ip头中 版本指协议版本ipv4还是ipv6, TOS表示包的优先级，0最高，1普通，2最低。系统优先处理高优先级的包 TTL:指的是的经过多少次路由，每经过一次路由TTL值减一 8位协议：表示上层协议是TCP还是UDP 4. 三层硬件设备 路由器（网关） 5. 路由器的类型? NAT网关：包在网络中转发改变源ip地址为网关地址，为了避免不同局域网内ip地址相同 转发网关：包在网络中转发不改变ip地址 6. 路由表都含有那些信息 至少包含目的网络、出口，下一跳网关。出口是指从哪个网口发出，下一跳网关指下一个路由器的地址。 7. 生成路由表的方式 - 静态路由：可以通过 ip route命令手动配置 - 动态路由：根据路由协议动态生成路由表，路由算法就是最短路径算法。比如：Dijkstra ## 3. 四层协议 1. udp和tcp的区别？ - tcp 是有连接的，通过连接传输的数据保证 无差错、不丢失、不重复、并且按序到达。udp 是无连接的，不保证传输的顺序和丢包 - tcp 是有状态的，udp是无状态的 - tcp 会进行拥塞控制，udp不会 - tcp 是面向字节流的，udp是基于数据报的一个个的发，一个一个的收 2. udp 的包格式 ![](../_resources/5A5F5E99-2A17-45BB-8DBF-8FFFE8CA08EE.jpg) 3. tcp 的包格式 ![](../_resources/309230D8-948A-4178-B852-C8D563C96666.jpg) 4. tcp 的三次握手过程 ![](../_resources/98401A55-4172-42F6-91FF-E85AD1B96874.jpg) ![](../_resources/11CAD420-0C31-4495-866F-FF53ED68D8B4.png) 内核为每个socket维护两个队列，一个是已经建立连接的队列，这时候三次握手完毕处于ESTABLISHED状态，一个未完全建立连接的队列，三次握手还未完成处于SYN_RECVD状态。 5. tcp三次握手的目的 - 建立连接 - 连接双方沟通双方包的起始序号 6. 为什么tcp是三次握手 因为三次握手的话，通信的双方都正好能确定自己发送的消息一去一回。多于三次握手的话就会造成信息的浪费 7. tcp的四次挥手 ![](../_resources/0FE22EEB-95C6-435E-A747-52F43B845970.jpg) 8. TIME_WAIT状态是为了解决什么问题？ - 解决客户端再发送完最后的ACK，服务端在没有收到ACK的情况下，等待客户端重发数据包 - 防止在没有TIME_WAIT的情况下，客户端退出腾出端口，该端口被新的应用占用后，接收到服务端上次发送来的包。 9. TIME_WAIT一般等多长时间？ 等2MSL(报文最大生存时间）一般是2min，只有在链接终止的一方才会进入TIME_WAIT 10. 如何解决服务端在2MSL后仍然没有接收到客户端发出的最后的ACK？ 因为服务端没有收到ACK， 因此会重新发送FIN。客户端在收到FIN后，因为已经等了2MSL所以会直接发送RST重置链接，这样服务端就知道客户端已经下线。 11. tcp的发送缓存和接收缓存 发送缓存：![](../_resources/6E74FDBA-9B92-459D-A4A9-DB218D634A40.jpg) 接收缓存 ![](../_resources/BC77354F-AA5E-462F-B853-18EBFD407590.jpg) 滑动串口和拥塞串口都是在这个缓存上实现的。 12. tcp如何保顺序性？ - 每个包都有序号，在建立连接的时候双发会商定双方序号的起始值， - 发送方在未收到前面序号包的ack时，不会向前滑动窗口。每次发送接收方接收窗口规定数量之内的包。 - 接收方在没收到序号靠前的包之前，不会确认已收到的序号靠后的包 13. tcp 靠重试防止丢包，重试的策略有那些？ - 超时重试: 对发出去的包要设定超时时间，在规定的超时时间内，没有收到ack的话，就重新发送，超时时间必须大于RTT(包往返时间)。 超时时间通过对RTT采样加权平均后得到。每次超时会把下一次超时时间设为原来值的两倍 - 快速重试：当客户端收到连续三个同一个包的ack时不等超时，马上重发下一个包。 14. tcp 如何解决接收方处理能力不足引起的网络问题? 通过滑动窗口，每个包的ACK都会标明接收窗口的大小，发送端按照接收窗口的规定数量，发送数据包 接收方应用读走一个字节，窗口增大一个字节。收到一个发送方字节窗口减小一个字节 当接收方应用读走的速度小于接收的速度则窗口减为0 当窗口减为0后，接收方并不是每读走一个字节就告诉发送方窗口加一，而是在读走一批后在增加窗口。防止刚读走马上填满的现象。 15. tcp 如何解决拥塞控制(网络处理能力不足)问题? - 激进做法：通过拥塞窗口解决，拥塞窗口初始值设置为1个包的大小，每次发送一个当收到ack后，拥塞窗口大小+1，变为一次发送两个包的，当收到两个包的ack时，拥塞窗口+2，以此类推，呈指数增长，这个阶段叫慢启动，直到达到阈值ssthresh 65535字节，则此时减小增长速度，呈线性增长。当增长到出现丢包或超时重传出现，则将ssthresh降为拥塞窗口的一半，而拥塞窗口的大小直接降为1。再重启启动 - 不激进做法：当发现快速重传的现象出现时，ssthresh降为拥塞串口大小，而拥塞串口降为原来的一般，再开始启动。 16. tcp监听的soket和传数据的socket是一个？ 不是 17. tcp的问题场景及优化？ 参考极客时间网络编程13讲 场景一：交互场景下，比如ssh登录后敲命令，每次传输的数据可能都很小，如果每次都敲完命令都传送，就可能造成浪费。 优化：使用Nagle算法，发送端把接下来的连续几个小数据包缓存起来，等接受到前一个小数据包的ACK时，一并发送出去。 可以通过一下函数关闭Nagle算法 `int on = 1; setsockopt(sock, IPPROTO_TCP, TCP_NODELAY, (void *)&on, sizeof(on));`{style=\"line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; color: #c1788b; padding: 4px 4px 2px 0; letter-spacing: -.3px;\"} 场景二：发送速率快时，大量的ack会消耗带宽， 优化：服务端累计ack，等到有数据要回复客户端时连同ack，一并回复。 18. udp 使用connect函数的意义？ 并不是为了建立连接，而是绑定当前socket和对端地址及端口的映射，以便似的底层icmp返回的对端不可达等错误信息能直接返回到当前socket上。负责发送将阻塞。同时connect可以提高udp发送接收性能，因为udp在每次发送和接收时都会建立上述映射关系，如果用connect提前建立映射，就可以提高性能。 19. 如何解决服务端重启导致的\"地址已经被使用问题\"? - 出现原因：\"地址已经被使用\"是因为服务端关闭时主动断开了链接，从而在发送完最后的ack后进入TIME_AWAIT状态，因此连接并未释放，而链接是有(srchost srcport dstport dsthost)唯一标识，因为重启后四元组相同，因此出现链接已经被使用 - 如何优化： `int on = 1; setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &on, sizeof(on));`{style=\"line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; color: #c1788b; padding: 4px 4px 2px 0; letter-spacing: -.3px;\"} - 优化原理： 重启后新链接的syn要比老连接结束时最大的syn大，这样通过序号就能区别出新老链接 重启后开启tcp_timestamps，使得新连接的时间戳比老连接的大，这样从时间戳上也能区分新老连接。 20. 如何理解tcp的流 TCP是面向连接的，也就是说，在连接持续的过程中，socket中收到的数据都是由同一台主机发出的，因此，保证数据是有序的到达就行，至于每次读取多少数据自己看着办。 而UDP是无连接的协议，也就是说，只要知道接收端的IP和端口，且网络是可达的，任何主机都可以向接收端发送数据。这时候，如果一次能读取超过一个报文的数据，则会乱套。所以tcp有粘包问题需要应用程序自己设计包分隔符。 21. tcp的故障模式有哪些？如何处理？ ![](../_resources/BAE913C9-0C63-4CC7-A57A-B103F30227FF.png) ## 4. 应用层协议 1. http 的包结构 header + body 请求报文格式 ![](../_resources/截屏2021-07-28%20上午12.33.06.png) 响应报文格式 ![](../_resources/截屏2021-07-28%20上午12.33.20.png) 2. http1.1的队头堵塞？ http的请求应答的模式，只有在收到上一个请求的应答才能发出下一个请求，导致在一条连接内，如果有一个请求响应较慢，就会造成请求排队的情况，这就叫队头阻塞 3. http1.1如何解决对头阻塞？ 同一个域名建立多个长连接 4. http如何传送大文件 - 数据压缩 - 分块传输：服务端通过响应头中Transfer-Encoding: chunked表示报文是分块传输的 - 范围请求：范围请求不是必须实现的功能，服务端必须通过Accept-Ranges: bytes告知客户端支持范围请求。请求头通过range:bytes=x-y, x1-y1 字段发起返回请求，x和y单位是字节。 5. http如何管理链接 http1.1之前是短连接，http1.1默认开启长连接。客户端可以在请求头中添加Connection: close关闭长连接，也可以通过Connection: keep-alive显示开启长连接 6. https的链接 分为两个部分，tls握手+秘钥通信 7. https的握手流程？ tls 1.2 ![](../_resources/FBF8C302-8D9E-4995-A6B9-EE0F8135A071.png) - 1和2主要是客户端和服务端协商要用的TLS版本和密码套件,以及交换随机数 - 3验证服务端证书，并用公钥生成随机字符串，并用公钥加密 - 4客户端发送用公钥生成的随机字符串到服务端。 - 5、6客户端和服务端用三个随机串及协商好的一套算法，生成对称秘钥 - 7、8客户端服务端互发fnished消息结束握手 8. http1和http2，http3有什么区别？ 1. http2： - TTP/2 必须先发送一个\"连接前言\"字符串，然后才能建立正式连接 - 采用HPACK算法实现头部压缩，hpack算法就是一种查表算法，通过在服务端和客户端两边建立一份索引表，如下，在传送头部数据时传送索引序号就行 ![](../_resources/截屏2021-08-09%20下午10.58.54.png) - http2传送的消息不再是Header+Body的形式的明文，而是分散的多个二进制帧。格式如下 ![](../_resources/截屏2021-08-09%20下午11.01.44.png) - http2采用了流的形式解决了http1的对头阻塞问题，同时实现了多路复用（一条连接内可以并发发送请求） 一个流id标志一次请求应答，流内是有严格的顺序 多个流可以乱序发送 流也可以设置优先级，让服务器优先处理 流id不能重用只能递增 - http2是基于tls的 ![](../_resources/截屏2021-08-09%20下午10.52.47.png) 2. http3: - 使用新的quic协议代替了tcp协议，解决了tcp的对头阻塞问题。 - QUIC 是一个新的传输层协议，建立在 UDP 之上，实现了可靠传输； - QUIC 内含了 TLS1.3，只能加密通信，支持 0-RTT 快速建连 - QUIC 的连接使用\"不透明\"的连接 ID，不绑定在\"IP 地址 + 端口\"上，支持\"连接迁移\" - QUIC 的流与 HTTP/2 的流很相似，但分为双向流和单向流 - HTTP/3 没有指定默认端口号，需要用 HTTP/2 的扩展帧\"Alt-Svc\"来发现。 # 2. linux网络管理 ## 1. linux的网络栈是怎样的？ ![](../_resources/20F3F5B8-82C4-481A-BACA-AF2082DBAE8B.png) 1. 内核中网络相关的数据结构： - sk_buf: 套接字缓存区，接收网卡数据，并在各层之间传递。且避免数据拷贝。多个sk_buf以双向链表的方式组织，构成了缓冲区等待队列。 - net_device: 描述了一个网卡设备,每个网卡设备是通过驱动程序注册到内核 在/sys/class/net/下能看到当前系统都有哪些网卡设备 2. 网络设备的关键属性 ## 2. linux的收发包流程是怎样的 ![](../_resources/14FFB5F1-A0BD-4C1F-B22C-3BB34165EB72.png) 1. 传统的收包流程 ![](../_resources/截屏2021-07-07%20下午11.47.50.png) ![](:/bd65d3ded9e04ba1b5dd50bd0bf0fde2 图中process_backlog流程如下 ![](../_resources/截屏2021-07-08%20下午11.19.19.png) - cpu接收到终端信号，执行网卡驱动提供的中断处理函数net_interrupt, - net_interrupt调用网卡驱动的net_rx 创建sk_buf， - net_rx 调用内核的netif_rx将sk_buf放入等待队列，并触发软中断 - 内核执行软中断处理函数net_rx_action - 软中断从队列中取出sk_buf，并交给协议层函数处理。 - 数据链路层协议去掉帧头、帧尾，交给网络层 - 网络层判断包的走向是交给上层还是转发，netfilter就在这层做处理 - 传输层将数处理完数据后将数据交给soket接收缓存，数据到达应用层。 2. NAPI(高速设备）收包流程 - 第一个分组到达，网络设备触发irq，驱动程序将设备(net_device)保存到轮询表上。 - 关闭接收IRQ net_rx_action 轮询轮询表上的设备，调用网卡驱动实现的poll函数来 只要设备的rx(接收缓存区）有分组就一直处理，直到全部处理完成 - 打开接收IRQ 注意： - 设备必须满足一下两个条件 1. 设备必须能保存分组到自己的缓冲区rx 2. 设备必须能够支持禁用接收IRQ - 支持NAPI的设备必须提供一个poll函数(用来轮询分组） 2. 发包流程 1. 首先应用层调用soketApi发送数据 2. 协议层从socket缓冲区取出数据，逐层处理，比如传输层加上传输层头，ip层加上ip头，执行路由并按照mtu的大小对报文分片。 3. 协议层处理完成后将数据放入sk_buf缓冲区 4. 触发软中断，软中断将sk_buf放入dm环形缓冲区并通知设备驱动发送数据。 注意： - 收发包流程一共涉及到俩次数据拷贝，从环形队列缓冲区到sk_buf, 从sk_buf到socket缓冲区 - 共涉及到3缓冲区，环形队列缓冲区属于网卡驱动层级，sk_buf用来串联协议流程，socket缓冲区与协议栈交互的应用层缓冲区。sk_buf由slab管理。 ## 3. linux的netfilter是怎样的？ 1. netfilter 是什么？ 它是一个linux的内核框架，位于网络层，它可以根据动态定义的条件来过滤和操作分组。iptables就是基于netflink做的 2. netfilter是如何工作的,及iptables如何使用 参考[映象笔记](https://app.yinxiang.com/fx/a045b80c-e70d-436a-9db4-e678ab859f00) ## 4. I/O模型 ### 1. IO多路复用 1. select/poll的实现原理 调用select会发生以下几步 - 从用户空间拷贝fd_set到内核空间 - 注册回调函数__pollwait；(这个函数的作用就是将当前进程加入设备自己特有的等待队列） - 遍历fd，调用设备的poll函数查看设备是否就绪 - 设备就绪，设置fd, 系统调用返回并将fd_set从内核空间拷贝到用户空间 - 设备未就绪则调用__pollwait将当前进程睡眠 2. epoll的实现原理 - 执行epoll_create时，在内核创建了红黑树和就绪链表 - 执行epoll_ctl时，如果增加socket句柄，则检查在红黑树中是否存在，存在立即返回，不存在则添加到树干上，然后向内核注册回调函数，用于当中断事件来临时向准备就绪链表中插入数据; - 执行epoll_wait时立刻返回准备就绪链表里的数据即可。 3. epoll事件的两种触发方式 - LT 只要一个描述符上事件没有处理完，就一直触发 - ET 只在从不就绪到就绪的那一刻触发一次 4. select、poll、epoll的区别 - select 有最大描述符数限制，32位机器通常是32*32，64位通常是32*64。poll没有，poll使用的是描述符链表。epoll也没有 - selec/poll每次就绪时，在用户空间都得遍历描述符集合，性能较低。epoll直接返回的就是就绪链表 - select/poll每次都得把描述符集合从用户空间拷贝到内核空间，epoll不需要。 5. select、poll的编程函数 - `int select(int maxfd, fd_set *readset, fd_set *writeset, fd_set *exceptset, const struct timeval *timeout);`{style=\"line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; color: #c1788b; padding: 4px 4px 2px 0; letter-spacing: -.3px;\"} - `int poll(struct pollfd *fds, unsigned long nfds, int timeout); // *fds 是个链表`{style=\"line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; color: #c1788b; padding: 4px 4px 2px 0; letter-spacing: -.3px;\"} ### 2. IO设计模式 1. 阻塞IO+进程 ![](../_resources/2A50E8C6-20B3-4F56-A45A-20473A528CE1.png) ``` {style=\"line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;\"} // 伪代码 fd = accept(listenfd) fork(fd) ``` 2. 阻塞IO+线程 ![](../_resources/65053FBD-5455-410A-859C-990E2D643058.png) ``` {style=\"line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;\"} // 伪代码 fd = accept(listenfd); thread(fd) ``` 3. 非阻塞IO + 事件通知 + 单线程（reactor) ![](../_resources/62FF9774-0B06-49F4-B166-F10EA8D25956.png) ``` {style=\"line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;\"} // 伪代码 // 等待可读，可写，可连接事件发生 epoll_wait(readfd, writefd, acceptfd) fd = accept(acceptfd) epoll.add(fd) // 每种事件分别交给线程池处理 threadpoll.put(readfd) threadpoll.put(writefd) ``` 4. 非阻塞IO + 事件通知 + 多线程 (主从reactor) ![](../_resources/DCD69796-C44E-41BC-84B4-0E6A384116B0.png) ``` {style=\"line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;\"} // 伪代码 // 主reactor, 只负责监听可连接事件，并将连接好的fd分发到从reactor线程 epoll_wait(acceptfd) fd = accept(acceptfd) subreactor.put(fd) // 从reactor 负责监听可读，可写事件，并将就绪事件交给读写线程池 epoll_wait(readfd, writefd) thradPoll.put(readfd) thradPoll.put(writefd) ``` 5. 异步IO + 多线程 ## 4. 网络工具 1. 查看网络配置 ifconfig(net-tools) ip(iprout2) 2. 显示套接字信息, 协议栈信息 netstat ss 3. 网络吞吐和pps(每秒传输的包数) sar(sysstat) -n 4. 连通性和延时 ping, hping3 traceroute 5. 抓包 tcpdump 6. 查看网卡信息 ethtool eth0 ",
    "url": "/docs/%E6%89%93%E9%93%81%E8%BF%98%E9%9C%80%E8%87%AA%E8%BA%AB%E7%A1%AC/%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86.html",
    
    "relUrl": "/docs/%E6%89%93%E9%93%81%E8%BF%98%E9%9C%80%E8%87%AA%E8%BA%AB%E7%A1%AC/%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86.html"
  },"36": {
    "doc": "网络调优与抓包分析",
    "title": "网络调优与抓包分析",
    "content": "1. tcpdump ``` #抓取指定源地址和端口的的流量 tcpdump src host 192.168.1.1 and tcp port 80 # 抓取指定目标地址和端口的流量 tcpdump dst host 192.168.1.1 and tcp port 80 # 抓取指定网卡，指定port 指定地址的流量 tcpdump -i eth0 tcp port 80 and host 192.168.1.1 # 抓包保存到文件，等待用wireshark分析 tcpdump -i eth0 tcp port 80 and host 192.168.1.1 -w capture_file.pcap #抓取本地lo的流量 tcpdump -i lo -nn ``` 2. tcpdump 抓包标志解析 1. P (PUSH): push标记告诉发送方， 立即处理这些接收到的数据， 而不是等待缓存区填满 2. S(SYN): 三次握手标记 3. F(FIN): 结束标记， 结束方发送次标记表示结束方准备关闭连接 4. R(RST): 连接重置标记， 用于突然中断连接（遇到了错误或者应用程序突然关闭)， 也可以用于拒绝非法的包，向关闭连接的一方发送数据，关闭方会返回rst， 向没有应用监听的端口发包会收到rst。 5.(无标志): 表示普通的数据包传输 6. ACK(确认)： 确认标记，用于确认接收到了之前发的数据 3. wireshark 中的标记 1. \\[ TCP Retransmission\\]: 标明相同的数据包被发送方发送了两次或多次。 重传通常是由于数据包丢失， 网络延迟或确认丢失导致的 2. \\[TCP Fast Retransmission\\]: 快重传， 用于在接收到多个Ack 确认时重传丢失的数据包 3. \\[TCP out-of-Order\\]: tcp乱序， 这意味着数据包没有按顺序到达， 可能由于网络路径不同导致的 4. \\[TCP Dup ACK 1#2\\]: 表示接收方已经收到了重复的确认包， 这通常是丢包的表现 5. TCP 分段丢失， 分段丢失可能不会直接显示， 通过观察序列号不连续来推断，如果发现序列号跳跃，通常意味着中间的某些数据包丢失了 6. \\[TCP Rest\\]: 连接重置 7. \\[TCP segment of a reassmbled PDU\\]: 表示当前收到的这个分段是一个在 传输过程中由于MTU限制被分割的更大数据单元的一部分 4. 那些情况下可以导致操作系统生成一个RST报文 1. 关闭正在等待的套接字： A 已经关闭， B仍然向A发送，B会收到一个RST 2. 异常终止应用程序：如果程序异常终止， 操作系统清理其打开的套接字，可能会发送RST 3. 无效的TCP状态： 如果一个包到达时，其状态于目标机器上的TCP连接状态不一致（例如， 一个对于机器来说非法的序列号），操作系统可能发送一个RST报文 5. **利用curl定位一个请求的各种网络耗时** ![f38c3bfa491be1c3545636a5042ec1b1.png](../_resources/f38c3bfa491be1c3545636a5042ec1b1.png) 6. 获取dns耗时 dig \\[域名\\] ",
    "url": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/%E7%BD%91%E7%BB%9C%E8%B0%83%E4%BC%98.html",
    
    "relUrl": "/docs/%E6%95%88%E7%8E%87%E5%B7%A5%E5%8E%82/%E7%BD%91%E7%BB%9C%E8%B0%83%E4%BC%98.html"
  },"37": {
    "doc": "计算机组成原理详解",
    "title": "计算机组成原理详解",
    "content": "# 计算机组成原理 ## 1. 入门篇 ### 1. 计算机的组成 任何一台计算机都是由： 运算器、控制器、存储器，输入输出设备组成。 如下图： ![](../_resources/9EF83160-CF4E-45CC-836B-0F17E589C619.png) ### 2. 衡量计算机的性能 1. 响应时间：执行一个程序要花多长时间 2. 吞吐率： 指的是一定时间范围我们能做多少事。 3. 性能 = 1/响应时间 | 程序的响应时间=cpu时钟周期数* 时钟周期时间 | 时钟周期时间(cpu执行一条指令的时间) = 1/cpu主频。| cpu时钟周期数 = 指令数 x 每条指令的平均时钟周期数 。 4. 如何优化响应时间：提高主频， 编译器优化减少指令数，cpu流水线减少一条指令的时钟周期。 5. 如何提高吞吐率：多核， 提升制程（也就是缩小晶体管的体积进而在单位面积上增加晶体管的数量）。提高主频和提升制程都容易造成cpu功耗太高。 6. 其他优化方法： - 加速大概率事件， 例如机器学习使用gpu进行优化 - 通过流水线提高性能 - 通过预测提高性能，例如 分支和冒险，局部性原理 ## 2. 指令和运算 ### 1. 指令 1. 程序如何变成计算机指令： 高级语言-汇编语言-机器码 2. 汇编指令和机器码是一一对应的。不同的指令集也就是不同的汇编码和不同的机器码。 3. 指令就是一个数，位数一般和cpu的位数相同。比如32位机器的指令一般也是32位。下图是32位MIPS指令， ![](../_resources/7C14CD1C-8118-4914-8B9B-FD29D07B96E8.png) 4. 指令的分类： - 算术类指令 - 数据传送类指令 - 逻辑类指令 - 条件分支类指令 - 无条件跳转类指令 5. 计算机的寄存器类型： - pc 寄存器：存储下一条将要执行的指令 - 指令寄存器：存储当前正在执行的指令 - 条件码寄存器：一些标志位，用来存储是否有进位，是否溢出，零标志条件吗（bool运算的标志） - 数据寄存器和地址寄存器。就是分别用来存储数据和地址的寄存器，其中既能存储地址也能存储数据的寄存器叫做通用寄存器。 6. if/else 编译成机器指令为cmp jne和 jmp 其中jmp是向后跳转。具体如下： ``` {style=\"line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;\"} if (r == 0) 3b: 83 7d fc 00 cmp DWORD PTR [rbp-0x4],0x0 3f: 75 09 jne 4a <main+0x4a // r==0 被编译成了 cmp和jne两条指令，cmp 比较r==0 去置位条件码寄存器的零标志位， jne 通过读取标志位决定 跳转还是不跳转。 { a = 1; 41: c7 45 f8 01 00 00 00 mov DWORD PTR [rbp-0x8],0x1 48: eb 07 jmp 51 <main+0x51 } else { a = 2; 4a: c7 45 f8 02 00 00 00 mov DWORD PTR [rbp-0x8],0x2 51: b8 00 00 00 00 mov eax,0x0 } ``` 7.while/for 编译成机器指令是jmp cmp和jle 其中jle向前跳转的。 ``` {style=\"line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;\"} for (int i = 0; i <= 2; i++) b: c7 45 f8 00 00 00 00 mov DWORD PTR [rbp-0x4],0x0 12: eb 0a jmp 1e //mov i=0 并直接跳转到cmp 指令。 { a += i; 14: 8b 45 f8 mov eax,DWORD PTR [rbp-0x4] 17: 01 45 fc add DWORD PTR [rbp-0x8],eax 1a: 83 45 f8 01 add DWORD PTR [rbp-0x4],0x1 1e: 83 7d f8 02 cmp DWORD PTR [rbp-0x4],0x2 22: 7e f0 jle 14 // 跳回上边位置 24: b8 00 00 00 00 mov eax,0x0 } ``` 8. 函数编译成指令如何执行 ``` {style=\"line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;\"} int static add(int a, int b) { 0: 55 push rbp // 基址指针寄存器 指向当前栈的底部 1: 48 89 e5 mov rbp,rsp // rsp 栈指针寄存器，指向当前栈顶 4: 89 7d fc mov DWORD PTR [rbp-0x4],edi 7: 89 75 f8 mov DWORD PTR [rbp-0x8],esi return a+b; a: 8b 55 fc mov edx,DWORD PTR [rbp-0x4] d: 8b 45 f8 mov eax,DWORD PTR [rbp-0x8] 10: 01 d0 add eax,edx } 12: 5d pop rbp 13: c3 ret 0000000000000014 <main: int main() { 14: 55 push rbp 15: 48 89 e5 mov rbp,rsp 18: 48 83 ec 10 sub rsp,0x10 int x = 5; 1c: c7 45 fc 05 00 00 00 mov DWORD PTR [rbp-0x4],0x5 int y = 10; 23: c7 45 f8 0a 00 00 00 mov DWORD PTR [rbp-0x8],0xa int u = add(x, y); 2a: 8b 55 f8 mov edx,DWORD PTR [rbp-0x8] 2d: 8b 45 fc mov eax,DWORD PTR [rbp-0x4] 30: 89 d6 mov esi,edx 32: 89 c7 mov edi,eax // 以上指令为参数赋值 34: e8 c7 ff ff ff call 0 <add // 函数调用被翻译成了call 指令，其中call指令能跳转到add函数地址，并将返回地址压栈 39: 89 45 f4 mov DWORD PTR [rbp-0xc],eax 3c: b8 00 00 00 00 mov eax,0x0 } 41: c9 leave 42: c3 ret // 弹出call指令压入的返回地址，然后跳回到该地址 如果函数中没有调用其他函数的话，编译器可以通过函数内联进行性能优化。 函数如果调用层次太深可能出现栈溢出问题 ``` ### 2. 程序如何执行 1. 高级语言-汇编码-机器码 - 执行 这个过程由两个部分组成 - 第一部分： 编译，汇编，链接 生成可执行文件 - 第二部分：装载器（loader) 把可执行文件装载到内存,变成数据和指令，cpu从内存中读取指令和数据真正开始执行。 ![](../_resources/6295F89E-B0D4-471B-A141-490255D63AB1.png) 2. linux下的可执行文件是ELF格式。ELF格式由以下几个部分组成: - .text Section （代码段）：用来保存程序的代码和指令 - .data Section（数据段）：用来保存程序里设置好的初始化数据信息 - .rel.text Section（重定位表）：保留了当前文件中我们在链接之前不知道的一些跳转地址，比如库函数printf - .symbol Section（符号表）：保留了当前文件里定义的函数及全局变量名称机和他们对应的虚拟内存地址 ![](../_resources/FADE12F7-054F-4A1E-8E2F-E76BAB771EEE.png) 3. 链接器的作用是扫描所有的目标文件，将所有符号表里的信息收集起来，构成一个全局的符号表，然后在根据重定位表，将之前不知道的函数挑战地址等修正为正确的内存地址。最后将所有目标文件的对应数据段，代码段进行一次合并，变成了最终的可执行代码。 4. 装载器的的加载要求 - 可执行文件占用的内存应该是连续的 - 加载器需要同时加载很多个程序，并且不能让程序自己规定在内存总加载的位置。解决这两个问题的方法就是内存映射（可执行文件中的地址都是虚拟地址，装载器在加载可执行文件的时候将虚拟地址映射成物理地址） 5. 内存映射的方法 - 内存分段 ![](../_resources/D188D7BD-9692-446C-9112-35D853741503.png) 说明： 装载器为每个程序寻找一块连续的内存空间，然后做好内存映射。优点就是解决了同时加载多个程序并不会造成内存地址冲突。缺点是 内存碎片 如图：![](../_resources/29D21C49-43C6-4B2E-B5EE-75B0CAB11A44.png) 两个剩余的128M空间是无法利用的。解决办法就是内存交换 可以先将Python程序交换到硬盘，在重新加载进来但不是原来的位置。但是也有性能瓶颈每次交换都是整个程序交换，太耗时。 - 内存分页 1. 背景：分页就是为了优化内存分段的问题，碎片化及发生交换时比较耗时 2. 原理：和分段把一大段连续的空间分配给整个程序相比，分页时将物理内存分成固定大小的页，linux中一页为4K 3. 优点：装载器在装载程序时不用把全部的程序装载到内存，装载器可以做好内存映射后，并不把页加载到物理内存，而是在程序运行过程中，需要用到内存页里的数据和指令时，再通过触发cpu的缺页异常将页加载到内存。这样减少了内存碎片化同时再内存换出的时候可以减少换出的内存大小从而减少换出耗时。 5. 链接可以分为动态链接和静态链接 - 静态链接： 就是将不同的目标文件链接到同一个目标文件。缺点：当多个程序共享一个库时，在链接的时候相当于每个程序都将共享库文件的内容合并到了当前文件。比较浪费内存空间。 - 动态链接：动态链接的内容并不是目标文件，而是已经加载到内存的共享库。linux下为.so文件，windows下为.dll文件。如图： ![](../_resources/3CA8F92B-3A83-4941-80D1-8E4EBB2BBC03.png) 说明： - 共享库中的指令代码必须是指令无关的，也就是不管加载到内存的那个位置都能运行。 - 虽然共享库用的都是同一段物理地址，但是在链接到每个程序中的虚拟地址不同 - 动态库中的函数和变量都使用相对与加载位置的相对对地址 - 实现动态链接： 动态库链接生成的ELF执行文件和静态链接的符号表和重定向表相似，对应的有plt表和GOT表，plt表里存了对应的函数名、全局变量名及在Got表中的位置，GOT表保存了具体的函数地址。GOT表存在于共享库的.data section，每个调用共享库的程序都加载一份Got表。当需要使用共享库的函数时再从GOT表中查询对应的函数地址。 我们的 GOT 表位于共享库自己的数据段里。GOT 表在内存里和对应的代码段位置之间的偏移量时钟是确定的 GOT 表里的数据，则是在我们加载一个个共享库的时候写进去的。类似于动态绑定。 ### 3. 计算机中数字，字符，浮点数的二进制形式 - 数字的二进制表示 1. 原码：将最高位作为符号位，其他数字为代表数值本身，0表示整数，1表示负数 2. 反码：如果是正数则和原码相同，如果是负数则保留符号位，其他位按位取反 3. 补码：如果是正数表示方法和原码一样，如果是负数则将数字的反码+1就是补码。负数使用补码的好处就是整数相加不需要任何的特殊处理，只是把他当成普通的二进制相加就能得到正确的结果。 - 字符的表示： 英文字符用ascii码，8位代表一个字符。其他语言比如中文一般用utf-8编码。 字符集和字符便码： unicode 是一个字符集，这个字符集收录了150万种语言，utf-8, utf-16 及gb2312是对unicode中的字符进行的一种编码方式 - 浮点数的二进制表示: 1. 定点数：32位数，用4个比特来表示0-9，则32位可以表示8个这样的数，我们用最左边的6个表示整数部分，最右边的两个数表示小数部分，这样的表示方式就是bcd便码，也就是定点数。小数点固定。缺点就是表示的数值范围不大，小数位数也不多。一般用在超市，银行等小数位数少的地方，这样的编码较为直观清晰 2. 浮点数：在计算机中用科学表示法来表示浮点数，也就是iEEE标准 ![](../_resources/73F2F1D9-B5C7-4139-8F22-D59FFED58B5D.png) ![](../_resources/7AD20078-0007-4B8D-89D9-7DF482F65765.png) 说明：指数位8位数 表示-127到+126的范围。 要表示0和一些特殊数，如图： ![](../_resources/1567CA9F-668C-4DD4-9959-3460E60088E0.png) 浮点数这样的表示也就决定了，浮点数只是近似值没有办法精确表示一个数，因此0.3+0.6 != 0.9 问题： 十进制数如何转换为二进制浮点数：整数部分直接转成二进制数，小数部分循环乘以2 浮点数如何相加：先对齐再计算，先对齐指的是小数点对齐。1.2 +12.3 浮点数相加的精度损失是什么： 浮点数相加如何解决精度损失 ### 3.处理器 #### 1. 指令周期、cpu周期或机器周期、时钟周期 - 时钟周期：cpu的最小时间间隔，主频的倒数 - 机器周期：从内存里面读一条指令的最短时间 - 指令周期： 执行一条指令通常需要取指，译码，执行，访存，回写等步骤，执行每个步骤通常需要一个时钟周期。这些时钟周期就组成了一个指令周期 #### 2. cpu所需要的硬件电路 ![](../_resources/E05AEFDC-182D-46DD-8D1E-4EDE276BC440.png) 说明：自动计数器就是pc寄存器 ## 3. CPU 并发设计 ### 1. 流水线 - 为什么需要流水线 相较于单指令周期的cpu，一条一条顺序执行，流水线的设计在同一个时钟周期内运行多条指令的多个阶段。提高了cpu的吞吐 - 流水线的原理 ![](../_resources/FD1FE0CD-7840-4671-BA79-68342A9DD833.png) 说明: 首先一条指令拆分成多个步骤，如上图，为五级流水线，同一个时钟周期可以运行不同指令的不同阶段。 - 流水线的缺陷 1. 流水线不是越多越好，每增加一级就多一级写到流水线寄存器的操作，就会增加一条指令的处理时间。同时也增加了功耗和散热的设备，因为增加了电路。 2. 流水线技术并不能缩短单条指令的响应时间，但是可以增加在运行很多条指令时候的吞吐 3. 必须解决好冒险的依赖关系 ### 2. 如何解决流水线冒险 - 冒险的分类 1. 结构冒险： cpu在同一个时钟周期，同时运行两条计算指令的不同阶段，但是这两个阶段可能用到同一个硬件电路 ![](../_resources/AF6EED7A-142E-45FB-A1B0-7A5BE65D8DD9.png) 解决方案：增加硬件资源，比如对于访问内存数据和指令的冲突，就是将cpu缓存分成指令缓存和数据缓存。也就是缓存采用哈佛结构 ![](../_resources/D9443BD4-5229-48D8-BEF7-E5B25AA3459C.png) 2. 数据冒险：同时**执行**的多个指令之间有数据依赖的情况。对应三种情况，先写后读，先读后写，写完在写。 解决方案: - 流水线停顿： 如果发现后边执行的指令会对前边执行的指令有数据层面的依赖，就在等等。缺点是插入过多的NOP操作，造成了性能下降 ![](../_resources/7269B3C1-0285-45A5-8658-6126F17FC4DC.png) - 操作数前推：如果下一条指令依赖上一条指令的结果，上一条指令在ALU执行完成后可以将结果直接发送给下一条指令执行。而不必等上一条指令写回到寄存器。再去取。 - 乱序执行：将没有依赖的指令发给不同的ALU功能单元同时执行。 ![](../_resources/D3F4A2D0-DBA4-4602-8DED-CA49A6CEDB7C.jpg) 说明: 上图RS功能就是指令分类，分发执行。重排缓存区会按照cpu取指令的顺序对指令结果重新排序。 3. 控制冒险：if/else等控制语句，只有执行后才知道下一条指令去哪取。这中间的等待延迟就是控制冒险。 解决方案： - 缩短分支延迟：在指令译码阶段提供条件判断与地址跳转的电路，使得等待时间变短。 - 分支预测 静态预测：就是假装分支不发生，也就是说只猜不跳转的情况，猜对的概率在50% 动态分支预测：一级分支预测，就是用1比特来记录当前分支的情况，根据当前分支情况预测下一次分支情况。二级分支预测就是用2个比特记录当前和上一次的分支情况。根据上两次的分支结果预测下一次分支情况。 ### 2. 超标量 通过增加硬件的方式，在取指，译码阶段也实现并行的处理方式。可以一次性从内存里面取出多条指令。然后发送给多个并行的指令译码器，最后交给不同功能的ALU去执行。使的ipc大于1， ![](../_resources/36B81F68-A7AC-4E19-AF65-7C263CEC3FB2.png) ### 3. 超线程和SIMD - 超线程 ![](../_resources/995D29F9-12B7-43CA-9660-F764D537C170.png) 超线程的目的就是让一个线程A的指令在流水线停顿的时候，去执行线程B的指令，这也是两套指令寄存器，pc寄存器，条件吗寄存器存在的意义。 - SIMD（单指令多数据流） ![](../_resources/5B0A0CE7-5ABA-44B8-B5E2-AE59CBA7D222.png) **SIMD指令**在获取数据和执行指令时都能并行，它是通过增加硬件的方式，一次性读取多个数据，并行执行。适用于大数据量数据并行的应用，比如向量运算，矩阵运算等。 ### 2. 异常 - 中断、陷进、故障、中止统称为异常 - 中断向量一般是有操作系统分配的，而异常是cpu预先分配的。 - 中断是指来自于cpu外部的的信号，打断当前程序的执行.一般是i/o设备信号 - 陷进是指程序员故意主动触发的异常。比如系统调用 - 故障是指程序运行过程中出现了错误，比如加法溢出。故障和中断及陷进的区别是故障在异常程序处理完成后任然回到当前指令，而不是去执行下一条指令。 - 中止是故障的一种，指不可恢复的故障 ![](../_resources/64377AC4-4E4C-4A97-90AF-1BF3B447BBC6.png) ### 3 处理器的其他架构 1. 指令集的分类: CISC(复杂指令) 、 RISC(精简指令） ![](../_resources/EAFF125A-F30E-4800-9314-013F2E327B00.png) 2. FPGA和ASIC FPGA: 现场可编程门阵列，这块芯片上有密密麻麻的门电路，可以通过编程控制这些门电路实现各种各样的硬件。 ASIC：为了专门用途而设计的一种芯片，比如tpu，GPU等 3. GPU: 专门为处理图形渲染而设计的一种处理器，现在也大量用作机器学习的训练 4. TPU: 专为深度学习的推断过程的计算而设计的一种处理器。 ## 4.存储与I/O系统 ### 1. 存储 #### 全景层次 ![](../_resources/10527D76-8FCE-4AFE-A2F0-FCA27EBAAAE4.png) #### 各存储器的性能差异 ![](../_resources/2AE93396-0E31-4709-A98E-A9546F30E44F.png) #### 局部性原理： 1. 时间局部性原理：如果一个数据被访问了，那么它在短时间之内还会被再次访问 2. 空间局部性原理：如果一个数据被访问了，那么和它相邻的数据也很快会被访问。 #### 高速缓存 1. 每个cpu 都有一个L1缓存和L2缓存，L3是多个cpu共享的， L1分为指令L1和数据L1 ![](../_resources/1EEE937F-D824-4656-A903-8A9B53F8F368.png) 2. cpu 从内存中读取数据到缓存是一块一块的来读取数据的，通常一个块的大小是64字节 3. cpu 无论数据在cache中存在与否，总是先读取cache 4. CPU 读取缓存数据的时候是一个字一个字读取的。 5. 内存数据加载到cache的映射机制： - cpu发出的内存地址 = 组标记 + 索引 + Offset - cache 中的block由 索引 + 有效位 + 组标记 + 数据 ![](../_resources/39FF731D-2699-4605-BEC6-B18157BA59E8.png) 6. cpu读取内存数据的步骤： - 根据内存地位，计算索引值 - 根据索引值定位到缓存块， 判断该缓存块有效。 - 对比内存高位的组标记和cache的组标记，确认cache中的数据是我们要访问的内存数据 - 根据内存地址的Offset位，从cache中对应的data block中获取对应的字 - 如果在2，3步骤中，cpu发现数据不是要访问的，那cpu就会访问内存，并把对应的block data 更新到cache中。同时更新对应的有效位和组标记的数据。 7. volatile： 确保我们对变量的读取和写入都一定会同步到主存里，而不经过cache 8. 高速缓存的写策略： - 写直达：每次数据写都写到主存里 - 写回：每次写入都写到cpu cache里。具体逻辑是：更新cache时如果cache中对应block是要更新的内存地址的数据则直接更新并标记为脏，如果不是则检测是否为脏，为脏则同步旧数据到内存，再将新数据更新到cache并标记为脏。 cpu从内存中加载数据到cache时，如果发现为脏先同步再加载。 9. MESI 保证解决多核cpu的缓存一致性 缓存一致性必须满足的条件：写传播，事务串行化(对数据更改的顺序不变)。 总线嗅探机制：这个机制可以实现写传播，即每一个cpu对缓存数据的更改都通过总线传播给其他cpu，其他CPU只需要监听总线做出反应就可以了。 实现缓存一致的策略： - 写失效：同一时间只能有一个cpu写，写完后广播一个\"失效\"请求，其他cpu将缓存置为失效。 - 写广播： 一个cpu的写入，广播给其它cpu, 让其他cpu也去更新 MESI(写失效机制)协议 1. M E S I 分别代表cache line的四种状态， M 已修改，E：独占(当前数据只有当前cpu有) S: 共享（所有cpu都有一份数据） I：代表失效。 2. cache line在 E和S状态时，代表数据是干净的也就是说主存一致的。 3. 共享状态下不能直接修改数据，需要通过广播失效信号，让其他cpu将他们缓存中的数据置位无效后才能更改。 4. MESI状态流转图如下 ![](../_resources/454156B1-8EFC-40B6-866E-C1E92185EC94.png) #### 虚拟内存： 1. 页表： 存储虚拟页号和物理页号映射的表 2. 最基本的虚拟地址转换为物理地址的步骤： - 虚拟地址切分为页号和偏移量。32为系统高20位为页号，低12位为偏移量 - 从页表，查询出对应的物理页号 - 直接拿物理页号+偏移量得出物理地址。 3. 多级页表 - 目的： 为了解决一级页表占用空间过大的问题。因为每个进程都有一张页表，32位系统每张一级页表4MB - 原理： ![](../_resources/1A7F78B2-060C-4E40-BE79-F173EAD41698.png) 通常多级页表是一个n叉的结构，4级页表存储多条3级页表，3级页表有存储多条2级页表，一次类推。但多级页表充分利用了内存的连续性。从而减少了很多2级，3级页表的存储。也就减少了空间的占用。 #### TLB 1. TLB 也是一块高速缓存，每个cpu都有一块这个芯片，也分为指令TLB和数据TLB. 也可以分成L1TLB和L2TLB 2. TLB 的作用是缓存虚拟地址到物理地址的转换结果(页表结果)，用来加速页表查询 3. 内存转换是有mmu这样的硬件来执行的,和TLB的交互都是由mmu来控制 ![](../_resources/430F51CB-7A5E-4931-B2D3-F85F4A616DA1.png) #### 安全与内存保护 1. 可执行空间保护：内存中除指令外，其他都不给与可执行权限，防止sql注入等漏洞 2. 地址空间布局随机化：将固定的内存布局改为随机的。思想类似于密码加盐. ![](../_resources/8F79F40C-3DD4-4265-AE0C-0252D54A0BB7.png) ### 2. I/O #### 总线 1. 总线介绍： cpu里的内存接口，直接和系统总线通信，然后系统总线在接入一个i/o桥接器，这个桥接器一遍接入内存总线，一遍接入I/O总线 ![](../_resources/5E38017C-EB5F-4FC1-9EA9-5BB6E2795829.png) 2. 总线的分类：数据总线，控制总线，地址总线 3. 总线裁决：解决多个设备共用总线的机制 #### 输入输出设备 组成：接口和实际设备。 接口：cpu通过总线实际和接口相连。也就是说cpu通过硬件接口控制设备。接口包含三类寄存器：状态寄存器，命令寄存器，数据寄存器，数据缓冲区，和一个设备控制电路 cpu是如何控制I/O设备的: 1. CPU向I/O设备写入需要传输的数据。 2. cpu发送一个命令到接口的命令寄存器。控制电路会根据命令控制设备做出相应的操作。 3. cpu 从状态寄存器中感知当前设备所处的状态。、 cpu如何I/O设备通信： 1. 内存映射I/O(MMIO): 内存和I/O设备共用cpu的地址总线，因此访问内存的指令就就可以访问I/O。I/O设备只需要监听地址线获取自己需要的数据就好。 2. 端口映射I/O(PMIO): 设备和内存不共享CPU的地址总线，而是有各自的地址空间也叫端口(抽象概念),这种方式一般cpu会提供专用的通信指令比如 in/out #### 机械硬盘 1. 机械硬盘的组成：盘面、磁头、悬臂 2. 硬盘的转数：每分钟旋转的圈数 3. 通常一个盘面有两个磁头，分别在正反两面 4. 硬盘随机访问的时间 = 平均延时（旋转盘面到指定扇区的时间）+ 平均寻道时间（悬臂移动到特定磁道的扇区的时间一般4-10ms） 5. 硬盘的IOPS(每秒随机访问次数)= 1s/硬盘随机访问时间。 6. 根据场景提高性能 - 原理就是缩短上边的随机访问时间，也就是缩短平均延时和平均寻道时间。 - 缩短平均寻到的方法一般是缩短定位磁道的行程，比如我们只用最外面的1/4或1/2磁道。 这样虽然缩短了定位磁道的行程，同时也减小了硬盘的容量。 #### SSD固态硬盘。 1. 基本组成：一个电容加一个电压计组合在一起，记录一个或多个比特。 2. ssd分类： - SLC: 一个电容加电压计的基本组合单元只能记录一个比特，这种数据存储方式叫slc - MLC: 一个电容能存储2个比特，TLC：一个电容里存储3个比特，QLC: 一个电容里存储4个比特。 3. 硬件构成：从上到下分别为，接口电路，FTL(闪存转换层）实际的I/O设备(裸片、平面、BLOCK、Page) ![](../_resources/7F304988-E745-4916-B65F-6FE7B4996F1B.png) 4. 写入：必须先擦除再写入，不能覆写. 写入和读取的基本单位是页。擦除的基本单位是块。 5. SSD的使用寿命就是每个块的擦写次数。SLC的擦写次数一般是10万次，MLC的擦写次数大概是一万次，TLC和QLC也就是几千次。 6. SSD必须进行磁盘整理，因为SSD擦除是按块擦除的，随着数据的删除和写入。某些块会形成数据空洞。这就必须有磁盘整理功能。将有效数据搬移，然后整块擦除，以备再写。 7. 磨损均衡： - 背景： 也就是说通过一定的机制让SSD将各个块的擦除次数，均匀的分摊到各个块上。FTL就是干这个的。 - FTL原理：类似于内存管理的页表，FTL存放了逻辑块地址到物理块地址的映射，操作系统通过逻辑地址访问硬盘，FTL将逻辑地址转换为对应的物理地址，同时FTL记录了每个块的擦写次数，当一个物理块擦写次数过多时，FTL可以更改逻辑地址映射到擦写次数少的物理块。对操作系统来说无感知。 8. TRIM指令：为了解决操作系统和SSD逻辑层块状态不匹配的问题，因为操作系统删除文件只是删除了inode，SSD逻辑层无法感知。因此当进行垃圾回收时由于不知道数据已经被删除。还会存在数据搬移动作，即消耗了性能，又缩短了使用寿命。 写入放大 = 实际的闪存写入数据量/系统通过FTL写入的数据量。写入放大机理就是随着SSD存储空间被占用的越来愈多，每一次写入新的数据，都由于存储空间不足不得不搬移大量的数据，从而造成性能变差。 9、优化点： - 尽量多读少写 - 尽可能写一个较大的数据快，这样就不容易出现磁盘碎片 - 持续的进行磁盘清理，确保有足够的空间进行写入。 - 只用SSD硬盘的一半空间，尽可能的降低写放大。 #### DMA - 什么是DMA: DMA可以理解为一个协处理器，帮助cpu完成对应的数据传输工作。cpu发送控制信息，告诉DMAC 从哪里到哪里传输多长的数据。具体的数据传输由DMA完成。 - 总线上的设备类型： 1. 主设备： 只有主设备才能主动发起数据传输 2. 从设备： 从设备只能被动的接受数据传输 - DMAC即是主设备又是从设备 - kafka通过零拷贝的技术优化数据传输 #### 硬件数据完整性 1. 单比特反转 2. 检测硬件数据反转的方法：采用有纠错检验的硬件，比如ECC内存。 3. 检错码：奇偶校验，缺点是只能检测一位 4. 纠错码：海明码 ",
    "url": "/docs/%E6%89%93%E9%93%81%E8%BF%98%E9%9C%80%E8%87%AA%E8%BA%AB%E7%A1%AC/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.html",
    
    "relUrl": "/docs/%E6%89%93%E9%93%81%E8%BF%98%E9%9C%80%E8%87%AA%E8%BA%AB%E7%A1%AC/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.html"
  }
}
